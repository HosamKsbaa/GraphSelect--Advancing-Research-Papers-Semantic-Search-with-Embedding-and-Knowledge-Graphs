Title,Link,Abstract
(1) A Prior-information-guided Residual Diffusion Model for Multi-modal PET Synthesis from MRI,https://typeset.io/papers/a-prior-information-guided-residual-diffusion-model-for-1as1diysv1,"Abstract: Alzheimer's disease (AD) leads to abnormalities in various biomarkers (i.e., amyloid-β and tau proteins), which makes PET imaging (which can detect these biomarkers) essential in AD diagnosis. However, the high radiation risk of PET imaging limits its scanning number within a short period, presenting challenges to the joint multi-biomarker diagnosis of AD. In this paper, we propose a novel unified model to simultaneously synthesize multi-modal PET images from MRI, to achieve low-cost and time-efficient joint multi-biomarker diagnosis of AD. Specifically, we incorporate residual learning into the diffusion model to emphasize inter-domain differences between PET and MRI, thereby forcing each modality to maximally reconstruct its modality-specific details. Furthermore, we leverage prior information, such as age and gender, to guide the diffusion model in synthesizing PET images with semantic consistency, enhancing their diagnostic value. Additionally, we develop an intra-domain difference loss to ensure that the intra-domain differences among synthesized PET images closely match those among real PET images, promoting more accurate synthesis, especially at the modality-specific information. Extensive experiments conducted on the ADNI dataset demonstrate that our method achieves superior performance both quantitatively and qualitatively compared to the state-of-the-art methods. All codes for this study have been uploaded to GitHub (https://github.com/Ouzaixin/ResDM)."
(2) Multimodal MRI-based Detection of Amyloid Status in Alzheimer's Disease Continuum,https://typeset.io/papers/multimodal-mri-based-detection-of-amyloid-status-in-3c284wotf4,"Abstract: Amyloid-
β
(A
β
) plaques in conjunction with hyperphosphorylated tau proteins in the form of neurofibrillary tangles are the two neuropathological hallmarks of Alzheimer's disease (AD). In particular, the accumulation of A
β
plaques, as evinced by the A/T/N (amyloid/tau/neurodegeneration) framework, marks the initial stage. Thus, the identification of individuals with A
β
positivity could enable early diagnosis and potentially lead to more effective interventions. Deep learning methods relying mainly on amyloid PET images have been employed to this end. However, PET imaging has some disadvantages, including the need of radiotracers and expensive acquisitions. Hence, in this work, we propose a novel multimodal approach that integrates information from structural, functional, and diffusion MRI data to discriminate A
β
status in the AD continuum. Our method achieved an accuracy of
0.762
±
0.04
. Furthermore, a \textit
explainability analysis (guided backpropagation) was performed to retrieve the brain regions that most influenced the model predictions. This analysis identified some key regions that were common across modalities, some of which were well-established AD-discriminative biomarkers and related to A
β
deposition, such as the hippocampus, thalamus, precuneus, and cingulate gyrus. Hence, our study demonstrates the potential viability of MRI-based characterization of A
β
status, paving the way for further research in this domain."
(3) An interpretable generative multimodal neuroimaging-genomics framework for decoding Alzheimer's disease,https://typeset.io/papers/an-interpretable-generative-multimodal-neuroimaging-genomics-19yxjmx1xr,"Abstract: Alzheimer's disease (AD) is the most prevalent form of dementia with a progressive decline in cognitive abilities. The AD continuum encompasses a prodormal stage known as Mild Cognitive Impairment (MCI), where patients may either progress to AD or remain stable. In this study, we leveraged structural and functional MRI to investigate the disease-induced grey matter and functional network connectivity changes. Moreover, considering AD's strong genetic component, we introduce SNPs as a third channel. Given such diverse inputs, missing one or more modalities is a typical concern of multimodal methods. We hence propose a novel deep learning-based classification framework where generative module employing Cycle GANs was adopted to impute missing data within the latent space. Additionally, we adopted an Explainable AI method, Integrated Gradients, to extract input features relevance, enhancing our understanding of the learned representations. Two critical tasks were addressed: AD detection and MCI conversion prediction. Experimental results showed that our model was able to reach the SOA in the classification of CN/AD reaching an average test accuracy of
0.926
±
0.02
. For the MCI task, we achieved an average prediction accuracy of
0.711
±
0.01
using the pre-trained model for CN/AD. The interpretability analysis revealed significant grey matter modulations in cortical and subcortical brain areas well known for their association with AD. Moreover, impairments in sensory-motor and visual resting state network connectivity along the disease continuum, as well as mutations in SNPs defining biological processes linked to amyloid-beta and cholesterol formation clearance and regulation, were identified as contributors to the achieved performance. Overall, our integrative deep learning approach shows promise for AD detection and MCI prediction, while shading light on important biological insights."
(4) Automated detection of Alzheimer’s disease: a multi-modal approach with 3D MRI and amyloid PET,https://typeset.io/papers/automated-detection-of-alzheimers-disease-a-multi-modal-4v5791ci18,"Abstract: Abstract Recent advances in deep learning and imaging technologies have revolutionized automated medical image analysis, especially in diagnosing Alzheimer’s disease through neuroimaging. Despite the availability of various imaging modalities for the same patient, the development of multi-modal models leveraging these modalities remains underexplored. This paper addresses this gap by proposing and evaluating classification models using 2D and 3D MRI images and amyloid PET scans in uni-modal and multi-modal frameworks. Our findings demonstrate that models using volumetric data learn more effective representations than those using only 2D images. Furthermore, integrating multiple modalities enhances model performance over single-modality approaches significantly. We achieved state-of-the-art performance on the OASIS-3 cohort. Additionally, explainability analyses with Grad-CAM indicate that our model focuses on crucial AD-related regions for its predictions, underscoring its potential to aid in understanding the disease’s causes."
(5) A hybrid multimodal machine learning model for Detecting Alzheimer's disease.,https://typeset.io/papers/a-hybrid-multimodal-machine-learning-model-for-detecting-1l9b6429g6,"Abstract: Alzheimer's disease (AD) diagnosis utilizing single modality neuroimaging data has limitations. Multimodal fusion of complementary biomarkers may improve diagnostic performance. This study proposes a multimodal machine learning framework integrating magnetic resonance imaging (MRI), positron emission tomography (PET) and cerebrospinal fluid (CSF) assays for enhanced AD characterization. The model incorporates a hybrid algorithm combining enhanced Harris Hawks Optimization (HHO) algorithm referred to as ILHHO, with Kernel Extreme Learning Machine (KELM) classifier for simultaneous feature selection and classification. ILHHO enhances HHO's search efficiency by integrating iterative mapping (IM) to improve population diversity and local escaping operator (LEO) to balance exploration-exploitation. Comparative analysis with other improved HHO algorithms, classic meta-heuristic algorithms (MHAs), and state-of-the-art MHAs on IEEE CEC2014 benchmark functions indicates that ILHHO achieves superior optimization performance compared to other comparative algorithms. The synergistic ILHHO-KELM model is evaluated on 202 AD Neuroimaging Initiative (ADNI) subjects. Results demonstrate superior multimodal classification accuracy over single modalities, validating the importance of fusing heterogeneous biomarkers. MRI + PET + CSF achieves 99.2 % accuracy for AD vs. normal control (NC), outperforming conventional and proposed methods. Discriminative feature analysis provides further insights into differential AD-related neurodegeneration patterns detected by MRI and PET. The differential PET and MRI features demonstrate how the two modalities provide complementary biomarkers. The neuroanatomical relevance of selected features supports ILHHO-KELM's potential for extracting sensitive AD imaging signatures. Overall, the study showcases the advantages of capitalizing on complementary multimodal data through advanced feature learning techniques for improving AD diagnosis."
(6) Multimodal diagnosis model of Alzheimer’s disease based on improved Transformer,https://typeset.io/papers/multimodal-diagnosis-model-of-alzheimers-disease-based-on-58r1k69vni,"Abstract: Abstract Purpose Recent technological advancements in data acquisition tools allowed neuroscientists to acquire different modality data to diagnosis Alzheimer’s disease (AD). However, how to fuse these enormous amount different modality data to improve recognizing rate and find significance brain regions is still challenging. Methods The algorithm used multimodal medical images [structural magnetic resonance imaging (sMRI) and positron emission tomography (PET)] as experimental data. Deep feature representations of sMRI and PET images are extracted by 3D convolution neural network (3DCNN). An improved Transformer is then used to progressively learn global correlation information among features. Finally, the information from different modalities is fused for identification. A model-based visualization method is used to explain the decisions of the model and identify brain regions related to AD. Results The model attained a noteworthy classification accuracy of 98.1% for Alzheimer’s disease (AD) using the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset. Upon examining the visualization results, distinct brain regions associated with AD diagnosis were observed across different image modalities. Notably, the left parahippocampal region emerged consistently as a prominent and significant brain area. Conclusions A large number of comparative experiments have been carried out for the model, and the experimental results verify the reliability of the model. In addition, the model adopts a visualization analysis method based on the characteristics of the model, which improves the interpretability of the model. Some disease-related brain regions were found in the visualization results, which provides reliable information for AD clinical research."
(7) Improving Alzheimer's Disease Diagnosis on Brain MRI Scans with an Ensemble of Deep Learning Models,https://typeset.io/papers/improving-alzheimer-s-disease-diagnosis-on-brain-mri-scans-54ik4xfw5o,"Abstract: Alzheimer's disease (AD) is a widespread neurolog-ical condition affecting millions globally. It gradually advances, leading to memory loss, cognitive deterioration, and a substantial decline in overall quality of life for those affected. AD patients experience memory decline, eroding cherished memories and straining relationships, while daily tasks become challenging. Numerous investigations have been conducted in this field, as the timely identification of Alzheimer's disease at its initial stage is of the utmost importance. A major limitation in this field is the predominant emphasis on using single fine-tuned CNN architecture or comparing pre-trained and custom CNN models for Alzheimer's detection, often on small datasets, which neglects a more comprehensive approach. Using smaller datasets can negatively impact deep learning modeling accuracy due to overfitting, limited representation, and poor generalization. This study addresses the current research problems and proposes an ensemble approach that combines predictions from various pre-trained models, including DenseNet-121, EfficientNet B7, ResNet-50, VGG-19, and also from a Custom CNN. The model averaging ensemble method was applied, a subset of the Stacking Ensemble, to two ADNI datasets, with Dataset-I being the larger. The goal was to assess the efficacy of this ensemble approach for accurate multiclass classification on ADNI datasets, where it successfully identified all classes despite differing sample volumes. A vast experiment was conducted on two distinct and widely recognized real-world datasets, resulting in accuracies of 99.96% and 98.90% respectively. Finally, the outcome of the research compared with recent research findings demonstrates the potential of our approach in advancing Alzheimer's disease detection by outperforming other benchmark approaches by a significant margin."
(8) Ensemble learning-based multimodal data analysis improving the diagnostic accuracy of Alzheimer's disease,https://typeset.io/papers/ensemble-learning-based-multimodal-data-analysis-improving-454xedfndr,"Abstract: Alzheimer's disease (AD) is a common neurodegenerative disease, whose early diagnosis is crucial for disease control and treatment. This study aims to explore the use of ensemble learning to analyze data from AD patients using multimodal inputs, including MRI image features extracted by convolutional neural networks (CNN), age, gender, APOE status and clinical functional scales. Firstly, we preprocess and extract the key image information features related to AD from MRI images. We then used multiple machine learning (ML) methods to build different classifiers, and combined these different classifiers by voting to obtain more accurate prediction results. Our method has been validated on a large AD patient database.The results demonstrated that the analysis of multimodal data can significantly improve the diagnostic accuracy of AD compared to single-mode data, while ensemble learning further improves the stability of the model."
(9) Multi-modal imaging genetics data fusion by deep auto-encoder and self-representation network for Alzheimer's disease diagnosis and biomarkers extraction,https://typeset.io/papers/multi-modal-imaging-genetics-data-fusion-by-deep-auto-4iy6mhqq32,"Abstract: Alzheimer's disease (AD) is an incurable neurodegenerative disease, so it is important to intervene in the early stage of the disease. Brain imaging genetics is an effective technique to identify AD-related biomarkers, which can early diagnosis of AD patients once they are clinically verified. With the development of medical imaging and gene sequencing techniques, the association analysis between multi-modal imaging data and genetic data has garnered increasing attention. However, current imaging genetics studies have problem with non-intuitive data fusion. Meanwhile, the characteristics of multi-modal imaging genetics data are high-dimensional, non-linearity, and fewer subjects, so it is necessary to select effective features. In this paper, a multi-modal data fusion framework by deep auto-encoder and self-representation (MFASN) was proposed for early diagnosis of AD. First, a multi-modality brain network was constructed by combining information from the resting-state functional magnetic resonance imaging (fMRI) data and structural magnetic resonance imaging (sMRI) data. Then, we utilized the deep auto-encoder to achieve non-linear transformations and select the informative features. A sparse self-representation module was employed to capture the multi-subspaces structure of the latent representation. At last, a multi-task structured sparse association model was developed to fully mine correlations between the genetic data and multi-modal brain network features. Experiments on AD neuroimaging initiative datasets proved the superiority of the proposed method, while discovering discriminative biomarkers were strongly associated with AD."
(10) Multi-Modal Deep Feature Integration for Alzheimer's Disease Staging,https://typeset.io/papers/multi-modal-deep-feature-integration-for-alzheimer-s-disease-4v82n018c9,"Abstract: Alzheimer's disease (AD) is one of the leading causes of dementia and 7th leading cause of death in the United States. The provisional diagnosis of AD relies on comprehensive examinations, including medical history, neurological and psychiatric examinations, cognitive assessments, and neuroimaging studies. Integrating diverse sets of clinical data, including electronic health records (EHRs), medical imaging, and genomic data, enables a holistic view of AD staging analysis. In this study, we propose an end-to-end deep learning architecture to jointly learn from magnetic resonance imaging (MRI), positron emission tomography (PET), EHRs, and genomics data to classify patients into AD, mild cognitive disorders, and controls. We conduct extensive experiments to explore different feature-level and intermediate-level fusion methods. Our findings suggest intermediate multiplicative fusion achieves the best stage prediction performance on the external validation dataset. Compared with unimodal baselines, we can observe that integrative approaches that leverage all four modalities demonstrate superior performance to baselines reliant solely on one or two modalities. In an age-wise comparison, we observe a unique pattern that all fusion methods exhibited superior performance in the earlier age brackets (50–70 years), with performance diminishing as the age group advanced (70–90 years). The proposed integration framework has the potential to augment our understanding of disease diagnosis and progression by leveraging complementary information from multimodal patient data."
