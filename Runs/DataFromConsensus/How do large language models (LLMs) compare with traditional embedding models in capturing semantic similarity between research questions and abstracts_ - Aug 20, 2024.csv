Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"Semantic Data Set Construction from Human Clustering and Spatial Arrangement","This study proposes a large-scale data set construction methodology using spatial multi-arrangement, which captures multi-way similarity judgments of verbs, potentially improving representation learning models for semantic clustering and similarity tasks.","Olga Majewska, Diana McCarthy, Jasper J. F. van den Bosch, N. Kriegeskorte, Ivan Vulic, A. Korhonen",2021,5,"Abstract Research into representation learning models of lexical semantics usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments. Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore ambiguity, or provide very specific sentential contexts that cannot then be used to generate a larger lexical resource. Furthermore, similarity between more than two items is not considered. We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase. The methodology uses a spatial multi-arrangement approach proposed in the field of cognitive neuroscience for capturing multi-way similarity judgments of visual stimuli. We have adapted this method to handle polysemous linguistic stimuli and much larger samples than previous work. We specifically target verbs, but the method can equally be applied to other parts of speech. We perform cluster analysis on the data from the first phase and demonstrate how this might be useful in the construction of a comprehensive verb resource. We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity. We demonstrate how the resultant data set can be used for fine-grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and semantic similarity. In particular, we find that stronger static word embedding methods still outperform lexical representations emerging from more recent pre-training methods, both on word-level similarity and clustering. Moreover, thanks to the data set’s vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as “Heat” or “Motion.”","","Computational Linguistics","1","10.1162/coli_a_00396","https://consensus.app/papers/data-construction-human-clustering-spatial-arrangement-majewska/7b3aad7ee1a45a52b56f7829b6098ebd/"
"Multi-sense embeddings through a word sense disambiguation process","Most Suitable Sense Annotation (MSSA) effectively disambiguates and annotates words by their specific senses, improving natural language understanding and outperforming more complex state-of-the-art systems.","Terry Ruas, W. Grosky, Akiko Aizawa",2019,33,"Abstract Natural Language Understanding has seen an increasing number of publications in the last few years, especially after robust word embeddings models became prominent, when they proved themselves able to capture and represent semantic relationships from massive amounts of data. Nevertheless, traditional models often fall short in intrinsic issues of linguistics, such as polysemy and homonymy. Any expert system that makes use of natural language in its core, can be affected by a weak semantic representation of text, resulting in inaccurate outcomes based on poor decisions. To mitigate such issues, we propose a novel approach called Most Suitable Sense Annotation (MSSA) , that disambiguates and annotates each word by its specific sense, considering the semantic effects of its context. Our approach brings three main contributions to the semantic representation scenario: (i) an unsupervised technique that disambiguates and annotates words by their senses, (ii) a multi-sense embeddings model that can be extended to any traditional word embeddings algorithm, and (iii) a recurrent methodology that allows our models to be re-used and their representations refined. We test our approach on six different benchmarks for the word similarity task, showing that our approach can produce state-of-the-art results and outperforms several more complex state-of-the-art systems.","","ArXiv","1","10.1016/j.eswa.2019.06.026","https://consensus.app/papers/multisense-embeddings-word-sense-disambiguation-process-ruas/368407071c955ef2b8ac41ca238f489d/"
"A reproducible survey on word embeddings and ontology-based methods for word similarity: Linear combinations outperform the state of the art","Word embedding models combining distributional and ontology-based information outperform the state-of-the-art in estimating word similarity and relatedness in AI, information retrieval, and natural language processing.","Juan J. Lastra-Díaz, J. Goikoetxea, Mohamed Ali Hadj Taieb, Ana M. García-Serrano, M. Benaouicha, Eneko Agirre",2019,78,"Abstract Human similarity and relatedness judgements between concepts underlie most of cognitive capabilities, such as categorisation, memory, decision-making and reasoning. For this reason, the proposal of methods for the estimation of the degree of similarity and relatedness between words and concepts has been a very active line of research in the fields of artificial intelligence, information retrieval and natural language processing among others. Main approaches proposed in the literature can be categorised in two large families as follows: (1) Ontology-based semantic similarity Measures (OM) and (2) distributional measures whose most recent and successful methods are based on Word Embedding (WE) models. However, the lack of a deep analysis of both families of methods slows down the advance of this line of research and its applications. This work introduces the largest, reproducible and detailed experimental survey of OM measures and WE models reported in the literature which is based on the evaluation of both families of methods on a same software platform, with the aim of elucidating what is the state of the problem. We show that WE models which combine distributional and ontology-based information get the best results, and in addition, we show for the first time that a simple average of two best performing WE models with other ontology-based measures or WE models is able to improve the state of the art by a large margin. In addition, we provide a very detailed reproducibility protocol together with a collection of software tools and datasets as supplementary material to allow the exact replication of our results.","","Eng. Appl. Artif. Intell.","1","10.1016/J.ENGAPPAI.2019.07.010","https://consensus.app/papers/survey-word-embeddings-ontologybased-methods-word-lastrad%C3%ADaz/2264a29184985b329f07c7d78159f7bb/"
"Comparative analysis of word embeddings in assessing semantic similarity of complex sentences","The complexity of sentences significantly impacts the performance of word embedding models in assessing semantic similarity, leading to a 10-20% decrease in Pearson's and Spearman's correlation.","Dhivya Chandrasekaran, Vijay K. Mago",2020,4,"Semantic textual similarity is one of the open research challenges in the field of Natural Language Processing. Extensive research has been carried out in this field and near-perfect results are achieved by recent transformer-based models in existing benchmark datasets like the STS dataset and the SICK dataset. In this paper, we study the sentences in these datasets and analyze the sensitivity of various word embeddings with respect to the complexity of the sentences. In this article, we build a complex sentence dataset comprising of 50 sentence pairs with associated semantic similarity values provided by 15 human annotators. Readability analysis is performed to highlight the increase in complexity of the sentences in the existing benchmark datasets and those in the proposed dataset. Further, we perform a comparative analysis of the performance of various word embeddings and language models on the existing benchmark datasets and the proposed dataset. The results show the increase in complexity of the sentences has a significant impact on the performance of the embedding models resulting in a 10-20% decrease in Pearson’s and Spearman’s correlation.","","IEEE Access","1","10.1109/ACCESS.2021.3135807","https://consensus.app/papers/analysis-word-embeddings-assessing-similarity-sentences-chandrasekaran/c39ea4365520540a88d9b04777e91df1/"
"Mufin: Enriching Semantic Understanding of Sentence Embedding using Dual Tune Framework","Our novel, efficient framework enhances multi-lingual text representations for NLU applications, outperforming state-of-the-art large language models with lesser training and resource requirements.","Koustava Goswami, Sourav Dutta, H. Assem",2021,1,"With the advancements of Natural Language Understanding (NLU), diverse industrial applications like user intent classification, smart chatbots, sentiment analysis and question answering have be-come a primary paradigm. Transformers-based multi-lingual language models such as XLM have performed significantly well in diverse semantic understanding and classification tasks. However, fine-tuning such large pre-trained architectures is resource and compute intensive, limiting its wide adoption in enterprise environments.We present a novel efficient and light-weight frame-work based on sentence embeddings to obtain enhanced multi-lingual text representations for domain-specific NLU applications. Our framework combines the concepts of up-projection, alignment and meta-embeddings enhancing the textual semantic similarity knowledge of smaller sentence embedding architectures. Extensive experiments on diverse cross-lingual classification tasks showcase the proposed framework to be comparable to state-of-the-art large language models (in mono-lingual and zero-shot settings), even with lesser training and resource requirements.","","2021 IEEE International Conference on Big Data (Big Data)","","10.1109/BigData52589.2021.9671614","https://consensus.app/papers/mufin-enriching-semantic-understanding-sentence-goswami/0f91be5c4f4452bb820ac53db628a26f/"
"DeeLM: Dependency-enhanced Large Language Model for Sentence Embeddings","DeeLM improves sentence embeddings by learning backward dependencies, outperforming baselines and achieving state-of-the-art performance across various semantic textual similarity tasks.","Xianming Li, Jing Li",2023,0,"Recent studies have proposed using large language models (LLMs) for sentence embeddings. However, most existing LLMs are built with an autoregressive architecture that primarily captures forward dependencies while neglecting backward dependencies. Previous work has highlighted the importance of backward dependencies in improving sentence embeddings. To address this issue, in this paper, we first present quantitative evidence demonstrating the limited learning of backward dependencies in LLMs. Then, we propose a novel approach called Dependency-Enhanced Large Language Model (DeeLM) to improve sentence embeddings. Specifically, we found a turning point in LLMs, where surpassing specific LLM layers leads to a significant performance drop in the semantic textual similarity (STS) task. STS is a crucial task for evaluating sentence embeddings. We then extract the layers after the turning point to make them bidirectional, allowing for the learning of backward dependencies. Extensive experiments demonstrate that DeeLM outperforms baselines and achieves state-of-the-art performance across various STS tasks.","","ArXiv","","10.48550/arXiv.2311.05296","https://consensus.app/papers/deelm-dependencyenhanced-large-language-model-sentence-li/3d98508848895c4d8c216a8b65072fe7/"
"KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation","KEPLER is a unified model that effectively integrates factual knowledge into pre-trained language representation models, producing effective text-enhanced knowledge embeddings for knowledge graphs.","Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juan-Zi Li, Jian Tang",2019,409,"Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.","","Transactions of the Association for Computational Linguistics","1","10.1162/tacl_a_00360","https://consensus.app/papers/kepler-unified-model-knowledge-embedding-pretrained-wang/84da1f249c4a555494d248aa3d88ed4f/"
"Scaling Sentence Embeddings with Large Language Models","In-context learning enables large language models to generate high-quality sentence embeddings, achieving comparable performance to current contrastive learning methods.","Ting Jiang, Shaohan Huang, Zhongzhi Luan, Deqing Wang, Fuzhen Zhuang",2023,2,"Large language models (LLMs) have recently garnered significant interest. With in-context learning, LLMs achieve impressive results in various natural language tasks. However, the application of LLMs to sentence embeddings remains an area of ongoing research. In this work, we propose an in-context learning-based method aimed at improving sentence embeddings performance. Our approach involves adapting the previous prompt-based representation method for autoregressive models, constructing a demonstration set that enables LLMs to perform in-context learning, and scaling up the LLMs to different model sizes. Through extensive experiments, in-context learning enables LLMs to generate high-quality sentence embeddings without any fine-tuning. It helps LLMs achieve performance comparable to current contrastive learning methods. By scaling model size, we find scaling to more than tens of billion parameters harms the performance on semantic textual similarity (STS) tasks. However, the largest model outperforms other counterparts and achieves the new state-of-the-art result on transfer tasks. We also fine-tune LLMs with current contrastive learning approach, and the 2.7B OPT model, incorporating our prompt-based method, surpasses the performance of 4.8B ST5, achieving the new state-of-the-art results on STS tasks. Our code is available at https://github.com/kongds/scaling_sentemb.","","ArXiv","","10.48550/arXiv.2307.16645","https://consensus.app/papers/scaling-sentence-embeddings-large-language-models-jiang/f5c6fb92876653a1a2cb0b6f3eac1fe2/"
"Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval","The LSTM-RNN model significantly outperforms existing methods in web document retrieval by automatically detecting salient keywords and assigning similar topics to different cells.","H. Palangi, L. Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying Song, R. Ward",2015,770,"This paper develops a model that addresses sentence embedding, a hot topic in current natural language processing research, using recurrent neural networks (RNN) with Long Short-Term Memory (LSTM) cells. The proposed LSTM-RNN model sequentially takes each word in a sentence, extracts its information, and embeds it into a semantic vector. Due to its ability to capture long term memory, the LSTM-RNN accumulates increasingly richer information as it goes through the sentence, and when it reaches the last word, the hidden layer of the network provides a semantic representation of the whole sentence. In this paper, the LSTM-RNN is trained in a weakly supervised manner on user click-through data logged by a commercial web search engine. Visualization and analysis are performed to understand how the embedding process works. The model is found to automatically attenuate the unimportant words and detect the salient keywords in the sentence. Furthermore, these detected keywords are found to automatically activate different cells of the LSTM-RNN, where words belonging to a similar topic activate the same cell. As a semantic representation of the sentence, the embedding vector can be used in many different applications. These automatic keyword detection and topic allocation abilities enabled by the LSTM-RNN allow the network to perform document retrieval, a difficult language processing task, where the similarity between the query and documents can be measured by the distance between their corresponding sentence embedding vectors computed by the LSTM-RNN. On a web search task, the LSTM-RNN embedding is shown to significantly outperform several existing state of the art methods. We emphasize that the proposed model generates sentence embedding vectors that are specially useful for web document retrieval tasks. A comparison with a well known general sentence embedding method, the Paragraph Vector, is performed. The results show that the proposed method in this paper significantly outperforms Paragraph Vector method for web document retrieval task.","","IEEE/ACM Transactions on Audio, Speech, and Language Processing","1","10.1109/TASLP.2016.2520371","https://consensus.app/papers/sentence-embedding-using-long-shortterm-memory-networks-palangi/412ff239075258a1b94681f9a825f3f2/"
"Enhancing Clinical Concept Extraction with Contextual Embedding","Contextual embeddings, trained on a large clinical corpus, achieve new state-of-the-art performance in clinical concept extraction, capturing valuable semantic information not accounted for by traditional word representations.","Yuqi Si, Jingqi Wang, Hua Xu, Kirk Roberts",2019,240,"OBJECTIVE
Neural network-based representations (""embeddings"") have dramatically advanced natural language processing (NLP) tasks, including clinical NLP tasks such as concept extraction. Recently, however, more advanced embedding methods and representations (eg, ELMo, BERT) have further pushed the state of the art in NLP, yet there are no common best practices for how to integrate these representations into clinical tasks. The purpose of this study, then, is to explore the space of possible options in utilizing these new models for clinical concept extraction, including comparing these to traditional word embedding methods (word2vec, GloVe, fastText).


MATERIALS AND METHODS
Both off-the-shelf, open-domain embeddings and pretrained clinical embeddings from MIMIC-III (Medical Information Mart for Intensive Care III) are evaluated. We explore a battery of embedding methods consisting of traditional word embeddings and contextual embeddings and compare these on 4 concept extraction corpora: i2b2 2010, i2b2 2012, SemEval 2014, and SemEval 2015. We also analyze the impact of the pretraining time of a large language model like ELMo or BERT on the extraction performance. Last, we present an intuitive way to understand the semantic information encoded by contextual embeddings.


RESULTS
Contextual embeddings pretrained on a large clinical corpus achieves new state-of-the-art performances across all concept extraction tasks. The best-performing model outperforms all state-of-the-art methods with respective F1-measures of 90.25, 93.18 (partial), 80.74, and 81.65.


CONCLUSIONS
We demonstrate the potential of contextual embeddings through the state-of-the-art performance these methods achieve on clinical concept extraction. Additionally, we demonstrate that contextual embeddings encode valuable semantic information not accounted for in traditional word representations.","","Journal of the American Medical Informatics Association : JAMIA","1","10.1093/jamia/ocz096","https://consensus.app/papers/enhancing-concept-extraction-contextual-embedding-si/3f78f3b7322851408a2132a4b50afe7d/"
