Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"SimLex-999: Evaluating Semantic Models With (Genuine) Similarity Estimation","SimLex-999 improves semantic model evaluation by quantifying similarity, enabling a wider range of applications and guiding the development of next-generation representation-learning architectures.","Felix Hill, Roi Reichart, A. Korhonen",2014,1230,"We present SimLex-999, a gold standard resource for evaluating distributional semantic models that improves on existing resources in several important ways. First, in contrast to gold standards such as WordSim-353 and MEN, it explicitly quantifies similarity rather than association or relatedness so that pairs of entities that are associated but not actually similar (Freud, psychology) have a low rating. We show that, via this focus on similarity, SimLex-999 incentivizes the development of models with a different, and arguably wider, range of applications than those which reflect conceptual association. Second, SimLex-999 contains a range of concrete and abstract adjective, noun, and verb pairs, together with an independent rating of concreteness and (free) association strength for each pair. This diversity enables fine-grained analyses of the performance of models on concepts of different types, and consequently greater insight into how architectures can be improved. Further, unlike existing gold standard evaluations, for which automatic approaches have reached or surpassed the inter-annotator agreement ceiling, state-of-the-art models perform well below this ceiling on SimLex-999. There is therefore plenty of scope for SimLex-999 to quantify future improvements to distributional semantic models, guiding the development of the next generation of representation-learning architectures.","","Computational Linguistics","1","10.1162/COLI_a_00237","https://consensus.app/papers/simlex999-evaluating-semantic-models-with-genuine-hill/6d748770bf39500aa88f001e584e1caa/"
"An information theoretic approach to improve semantic similarity assessments across multiple ontologies","Our approach accurately measures semantic similarity across multiple ontologies, improving the accuracy of Information Content-based measures in multiple knowledge bases.","Montserrat Batet, S. Harispe, S. Ranwez, David Sánchez, Vincent Ranwez",2014,38,"Semantic similarity has become, in recent years, the backbone of numerous knowledge-based applications dealing with textual data. From the different methods and paradigms proposed to assess semantic similarity, ontology-based measures and, more specifically, those based on quantifying the Information Content (IC) of concepts are the most widespread solutions due to their high accuracy. However, these measures were designed to exploit a single ontology. They thus cannot be leveraged in many contexts in which multiple knowledge bases are considered. In this paper, we propose a new approach to achieve accurate IC-based similarity assessments for concept pairs spread throughout several ontologies. Based on Information Theory, our method defines a strategy to accurately measure the degree of commonality between concepts belonging to different ontologies--this is the cornerstone for estimating their semantic similarity. Our approach therefore enables classic IC-based measures to be directly applied in a multiple ontology setting. An empirical evaluation, based on well-established benchmarks and ontologies related to the biomedical domain, illustrates the accuracy of our approach, and demonstrates that similarity estimations provided by our approach are significantly more correlated with human ratings of similarity than those obtained via related works.","","Inf. Sci.","1","10.1016/J.INS.2014.06.039","https://consensus.app/papers/information-approach-improve-similarity-assessments-batet/efac083491e254a98e19fd0e805a116d/"
"Cross domain-based ontology construction via Jaccard Semantic Similarity with hybrid optimization model","The Circling Insisted-Rider Optimization Algorithm (CI-ROA) effectively optimizes ontology construction by combining Whale Optimization Algorithm (WOA) and Rider Optimization Algorithm (ROA).","Shital Kakad, Sudhir Dhage",2021,11,"Abstract Semantic web technology seems to be in the infant stage as only little efforts have been taken on ontology construction with cross-domain application. This paper intends to take an effort on a new workspace, in which the ontology construction model under cross-domain application is performed. The core concern of this work is on two decision-making process namely data filtering and data annotation. Certain process is followed in this work: (i) Preprocessing (ii) Proposed Jaccard Similarity Evaluation (iii) Data filtering and Outlier Detection (iv)Semantic annotation and clustering. More particularly, data filtering is performed based on the evaluated similarity function. The outliers are identified and grouped separately. The data annotation is performed based on the semantics and thereby the clustering process takes place to form the ontology precisely. This clustering process obviously relies to the optimization crisis as the optimal centroid selection becomes the greatest issue. In order to solve this, this paper extends with the introduction of a hybrid algorithm named Circling Insisted-Rider Optimization Algorithm (CI-ROA), which hybrids the concept of Whale Optimization Algorithm (WOA) and Rider Optimization Algorithm (ROA), respectively. Finally, the performance of proposed work is compared and proved over other state-of-the-art models.","","Expert Syst. Appl.","1","10.1016/J.ESWA.2021.115046","https://consensus.app/papers/cross-domainbased-construction-jaccard-semantic-kakad/a7ce27e17ec75fe78405b408d32647fb/"
"Feature-based approaches to semantic similarity assessment of concepts using Wikipedia","This paper proposes novel feature-based similarity assessment methods using Wikipedia, which overcome limitations and drawbacks in existing methods, and shows good human correlation.","Yuncheng Jiang, Xiaopei Zhang, Yong Tang, Ruihua Nie",2015,90,"Abstract Semantic similarity assessment between concepts is an important task in many language related applications. In the past, several approaches to assess similarity by evaluating the knowledge modeled in an (or multiple) ontology (or ontologies) have been proposed. However, there are some limitations such as the facts of relying on predefined ontologies and fitting non-dynamic domains in the existing measures. Wikipedia provides a very large domain-independent encyclopedic repository and semantic network for computing semantic similarity of concepts with more coverage than usual ontologies. In this paper, we propose some novel feature based similarity assessment methods that are fully dependent on Wikipedia and can avoid most of the limitations and drawbacks introduced above. To implement similarity assessment based on feature by making use of Wikipedia, firstly a formal representation of Wikipedia concepts is presented. We then give a framework for feature based similarity based on the formal representation of Wikipedia concepts. Lastly, we investigate several feature based approaches to semantic similarity measures resulting from instantiations of the framework. The evaluation, based on several widely used benchmarks and a benchmark developed in ourselves, sustains the intuitions with respect to human judgements. Overall, several methods proposed in this paper have good human correlation and constitute some effective ways of determining similarity between Wikipedia concepts.","","Inf. Process. Manag.","1","10.1016/J.IPM.2015.01.001","https://consensus.app/papers/featurebased-approaches-similarity-assessment-concepts-jiang/926065946fce53f78defa02449933e1d/"
"Evaluation of taxonomic and neural embedding methods for calculating semantic similarity","Taxonomic similarity measures rely on shortest path length, edge-counting is free from sense distribution bias, and neural embeddings with concept relations can improve semantic similarity prediction.","Dongqiang Yang, Yanqin Yin",2021,2,"Abstract Modelling semantic similarity plays a fundamental role in lexical semantic applications. A natural way of calculating semantic similarity is to access handcrafted semantic networks, but similarity prediction can also be anticipated in a distributional vector space. Similarity calculation continues to be a challenging task, even with the latest breakthroughs in deep neural language models. We first examined popular methodologies in measuring taxonomic similarity, including edge-counting that solely employs semantic relations in a taxonomy, as well as the complex methods that estimate concept specificity. We further extrapolated three weighting factors in modelling taxonomic similarity. To study the distinct mechanisms between taxonomic and distributional similarity measures, we ran head-to-head comparisons of each measure with human similarity judgements from the perspectives of word frequency, polysemy degree and similarity intensity. Our findings suggest that without fine-tuning the uniform distance, taxonomic similarity measures can depend on the shortest path length as a prime factor to predict semantic similarity; in contrast to distributional semantics, edge-counting is free from sense distribution bias in use and can measure word similarity both literally and metaphorically; the synergy of retrofitting neural embeddings with concept relations in similarity prediction may indicate a new trend to leverage knowledge bases on transfer learning. It appears that a large gap still exists on computing semantic similarity among different ranges of word frequency, polysemous degree and similarity intensity.","","Natural Language Engineering","1","10.1017/S1351324921000279","https://consensus.app/papers/evaluation-embedding-methods-calculating-similarity-yang/b173931791c156b38bc0ceac63340417/"
"Efficient model similarity estimation with robust hashing","Our robust hashing technique efficiently estimates model similarity in model-driven engineering, reducing time and effort for finding similar models in large repositories.","Salvador Martínez, S. Gérard, Jordi Cabot",2021,5,"As model-driven engineering (MDE) is increasingly adopted in complex industrial scenarios, modeling artefacts become a key and strategic asset for companies. As such, any MDE ecosystem must provide mechanisms to protect and exploit them. Current approaches depend on the calculation of the relative similarity among pairs of models. Unfortunately, model similarity calculation mechanisms are computationally expensive which prevents their use in large repositories or very large models. In this sense, this paper explores the adaptation of the robust hashing technique to the MDE domain as an efficient estimation method for model similarity. Indeed, robust hashing algorithms (i.e., hashing algorithms that generate similar outputs from similar input data) have proved useful as a key building block in intellectual property protection, authenticity assessment and fast comparison and retrieval solutions for different application domains. We present a detailed method for the generation of robust hashes for different types of models. Our approach is based on the translation to the MDE domain of diverse techniques such as summary extraction, minhash generation and locality-sensitive hash function families, originally developed for the comparison and classification of large datasets. We validate our approach with a prototype implementation and show that: (1) our approach can deal with any graph-based model representation; (2) a strong correlation exists between the similarity calculated directly on the robust hashes and a distance metric calculated over the original models; and (3) our approach scales well on large models and greatly reduces the time required to find similar models in large repositories.","","Software and Systems Modeling","1","10.1007/s10270-021-00915-9","https://consensus.app/papers/model-similarity-estimation-robust-hashing-mart%C3%ADnez/9272fcd1e39654a48bd9b51a6489d851/"
"A Semantic Similarity Evaluation Method and a Tool Utilised in Security Applications Based on Ontology Structure and Lexicon Analysis","The proposed semantic similarity evaluation method and ETOSE plugin can effectively identify hidden associations and patterns in knowledge bases, aiding in security applications like financial fraud identification.","M. Chmielewski, Małgorzata Paciorkowska, Maciej Kiedrowicz",2017,6,"This paper discusses a semantic similarity evaluation method within semantic models represented as ontologies or an instance bases. The capabilities of the method can be used for semantic pattern recognition within knowledge bases, which can be utilised by analytical tools especially in the security domain. The specificity of security applications requires methods for analysis of hidden, in direct, comprehensive and versatile data in search for new knowledge. Proposed method and its implementation in form of ETOSE plugin serves as an analytical process evaluating instance bases. The mechanisms has been designed to operate as a data flow interceptor, collecting the data and transforming them into instances expressed in a specific domain ontology (set of ontology modules). After such migration ETOSE plugin performs evaluation of instance base and provides the analyst mechanisms for identification of hidden associations and patterns. The quantitative approach has been applied in financial fraud identification tasks where certain templates of behaviour and associations can be described. Proposed method and tool utilize structural and lexicon comparison of compared ontologies in order to deliver multicriteria evaluation of concepts, relationships and indirectly implemented axioms. The paper demonstrates the theoretical side of designed method as well as practical examples, developed ontologies and analytical environment application.","","2017 Fourth International Conference on Mathematics and Computers in Sciences and in Industry (MCSI)","","10.1109/MCSI.2017.46","https://consensus.app/papers/similarity-evaluation-method-tool-utilised-security-chmielewski/19b46271050f5894a92f4fef2598a02a/"
"Determining Semantic Similarity among Entity Classes from Different Ontologies","This study presents a semantic similarity model that accounts for differences in ontology specifications and matches synonym sets, semantic neighborhoods, and distinguishing features to determine similar entity classes across different ontologies.","Michael A. Rodriguez, M. Egenhofer",2003,1012,"Semantic similarity measures play an important role in information retrieval and information integration. Traditional approaches to modeling semantic similarity compute the semantic distance between definitions within a single ontology. This single ontology is either a domain-independent ontology or the result of the integration of existing ontologies. We present an approach to computing semantic similarity that relaxes the requirement of a single ontology and accounts for differences in the levels of explicitness and formalization of the different ontology specifications. A similarity function determines similar entity classes by using a matching process over synonym sets, semantic neighborhoods, and distinguishing features that are classified into parts, functions, and attributes. Experimental results with different ontologies indicate that the model gives good results when ontologies have complete and detailed representations of entity classes. While the combination of word matching and semantic neighborhood matching is adequate for detecting equivalent entity classes, feature matching allows us to discriminate among similar, but not necessarily equivalent entity classes.","","IEEE Trans. Knowl. Data Eng.","1","10.1109/TKDE.2003.1185844","https://consensus.app/papers/determining-similarity-among-entity-classes-different-rodriguez/483c445879505982977ef61c92b5d4d1/"
"A Cross-Domain Semantic Similarity Measure and Multi-Source Domain Adaptation in Sentiment Analysis","Using enhanced cross-entropy measures in multi-source domain adaptation models improves sentiment analysis accuracy by 3.66% to 9.09% when training on different domains.","Dipak Patel, Kiran R. Amin",2022,2,"Domain adaptation becomes crucial when there is a lack of labelled data in various domains. The accuracy of traditional machine learning models degrades largely if they are trained on one domain (called the source or training domain) and classify the data of a different domain (called the target domain or test domain, which is different from the source domain). The machine needs to train on a corresponding domain to improve the classification accuracy, but labelling each new domain is a complex and time-consuming task. Hence, the domain adaptation technique is required to solve the issue of data labeling. The similarity measure plays a vital role in selecting important pivot features from the target domain that match source domains. This research article has introduced an enhanced cross-entropy measure for matching the normalized frequency distribution of different domains and found an important domain-specific feature set. In addition, the technique of using enhanced cross entropy measures is proposed in the multi-source domain adaptation model to effectively classify the target domain data. The result shows that there is an improvement of 3.66% to 9.09% using our approach.","","2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","","10.1109/ICAISS55157.2022.10011051","https://consensus.app/papers/crossdomain-semantic-similarity-measure-multisource-patel/ec7c2c2a11405992a291af7b9d9ffefa/"
"A knowledge-intensive approach to process similarity calculation","Our novel distance measure improves process similarity calculation by incorporating domain knowledge and complex control flow constructs, providing more reliable results in real-world applications like stroke management.","S. Montani, G. Leonardi, S. Quaglini, A. Cavallini, G. Micieli",2015,29,"Abstract Process model comparison and similar processes retrieval are key issues to be addressed in many real world situations, and particularly relevant ones in some applications (e.g., in medicine), where similarity quantification can be exploited in a quality assessment perspective. Most of the process comparison techniques described in the literature suffer from two main limitations : (1) they adopt a purely syntactic (vs. semantic) approach in process activity comparison, and/or (2) they ignore complex control flow information (i.e., other than sequence). These limitations oversimplify the problem, and make the results of similarity-based process retrieval less reliable, especially when domain knowledge is available, and can be adopted to quantify activity or control flow construct differences. In this paper, we aim at overcoming both limitations , by introducing a framework which allows to extract the actual process model from the available process execution traces, through process mining techniques, and then to compare (mined) process models, by relying on a novel distance measure . The novel distance measure, which represents the main contribution of this paper, is able to address issues (1) and (2) above, since: (1) it provides a semantic, knowledge-intensive approach to process activity comparison, by making use of domain knowledge; (2) it explicitly takes into account complex control flow constructs (such as AND and XOR splits/joins), thus fully considering the different semantic meaning of control flow connections in a reliable way. The positive impact of the framework in practice has been tested in stroke management, where our approach has outperformed a state-of-the art literature metric on a real world event log, providing results that were closer to those of a human expert. Experiments in other domains are foreseen in the future.","","Expert Syst. Appl.","1","10.1016/J.ESWA.2015.01.027","https://consensus.app/papers/approach-process-similarity-calculation-montani/95b6847491e354b9a7f11a003e52fcfe/"
