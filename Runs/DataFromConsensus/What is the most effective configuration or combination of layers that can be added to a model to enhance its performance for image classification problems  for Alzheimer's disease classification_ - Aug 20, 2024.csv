Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"An Improved LeNet-Deep Neural Network Model for Alzheimer’s Disease Classification Using Brain Magnetic Resonance Images","The modified LeNet model, using Min-Pooling and MaxPooling layers, achieves an average performance rate of 96.64% for Alzheimer's disease classification using brain magnetic resonance images compared to other commonly used DNN models.","Ruhul Amin Hazarika, Ajitha T. Abraham, D. Kandar, A. K. Maji",2021,11,"Alzheimer’s Disease (AD) is a psychological disorder in elderly people which causes severe intellectual disabilities. Proper processing of neuro-images can provide differences in brain tissues which may help in diagnosing the disease more effectively. But, due to the complex structures, this is a challenge in differentiating the brain tissues and classifying AD using traditional classification mechanisms. Deep Neural Network (DNN) is a machine learning technique that has the ability to absorb the most important information for classifying an object accurately. LeNet is a popular DNN based model with a simple and effective architecture that also consumes very less implementation time. As like most of the DNN models, LeNet also uses MaxPooling layer for dimensionality reduction by eliminating the information of minimum valued elements. In brain images low intensity valued pixels also may contain very important features. To keep the minimum valued elements too in the network, we have created a separate layer that performs Min-Pooling operation. MinPooling and MaxPooling layers are then concatenated together. Finally, we have replaced all MaxPooling Layers in LeNet by the concatenated layers. We have analysed and compared the performances of modified LeNet model with 20 other most commonly used DNN models, and some of the related works. It is observed that, the modified LeNet model achieved the highest performances. It is also observed that, original LeNet model can classify AD with a performance rate of 80%, whereas, the proposed modified LeNet model achieved an average performance rate of 96.64%.","","IEEE Access","1","10.1109/ACCESS.2021.3131741","https://consensus.app/papers/improved-lenetdeep-neural-network-model-alzheimer-hazarika/adf22a2d4cd65b1681fbc54b2779565e/"
"A Stacking Framework for Multi-Classification of Alzheimer's Disease Using Neuroimaging and Clinical Features.","The Stacking framework, combining neuroimaging and clinical features, significantly improves Alzheimer's disease diagnosis accuracy compared to using only sMRI data alone.","Durong Chen, Fuliang Yi, Yao Qin, Jiajia Zhang, Xiaoyan Ge, Hongjuan Han, Jing Cui, Wenlin Bai, Yan Wu, Hongmei Yu",2022,2,"BACKGROUND
Alzheimer's disease (AD) is a severe health problem. Challenges still remain in early diagnosis.


OBJECTIVE
The objective of this study was to build a Stacking framework for multi-classification of AD by a combination of neuroimaging and clinical features to improve the performance.


METHODS
The data we used were from the Alzheimer's Disease Neuroimaging Initiative database with a total of 493 subjects, including 125 normal control (NC), 121 early mild cognitive impairment, 109 late mild cognitive impairment (LMCI), and 138 AD. We selected structural magnetic resonance imaging (sMRI) features by voting strategy. The imaging features, demographic information, Mini-Mental State Examination, and Alzheimer's Disease Assessment Scale-Cognitive Subscale were combined together as classification features. We proposed a two-layer Stacking ensemble framework to classify four types of people. The first layer represented support vector machine, random forests, adaptive boosting, and gradient boosting decision tree; the second layer was a logistic regression classifier. Additionally, we analyzed performance of only sMRI feature and combined features and compared the proposed model with four base classifiers.


RESULTS
The Stacking model combined with sMRI and non-imaging features outshined four base classifiers with an average accuracy of 86.96% . Compared with using sMRI data alone, sMRI combined with non-imaging features significantly improved diagnostic accuracy, especially in NC versus LMCI and LMCI versus AD by 14.08% .


CONCLUSION
The Stacking framework we used can improve performance in diagnosis of AD using combined features.","non-rct observational study","Journal of Alzheimer's disease : JAD","1","10.3233/jad-215654","https://consensus.app/papers/stacking-framework-multiclassification-alzheimers-chen/21bcd3e3b5de5448b3ee73ae03c83134/"
"Transfer Learning With Intelligent Training Data Selection for Prediction of Alzheimer’s Disease","Transfer learning with intelligent training data selection, using pre-trained weights from natural images, can improve Alzheimer's disease detection from neuroimaging data, with a 4% and 7% increase in accuracy.","N. Khan, Nabila Abraham, Marcia Hon",2019,95,"Detection of Alzheimer’s disease (AD) from neuroimaging data such as MRI through machine learning has been a subject of intense research in recent years. The recent success of deep learning in computer vision has progressed such research. However, common limitations with such algorithms are reliance on a large number of training images, and the requirement of careful optimization of the architecture of deep networks. In this paper, we attempt solving these issues with transfer learning, where the state-of-the-art VGG architecture is initialized with pre-trained weights from large benchmark datasets consisting of natural images. The network is then fine-tuned with layer-wise tuning, where only a pre-defined group of layers are trained on MRI images. To shrink the training data size, we employ image entropy to select the most informative slices. Through experimentation on the ADNI dataset, we show that with the training size of 10 to 20 times smaller than the other contemporary methods, we reach the state-of-the-art performance in AD vs. NC, AD vs. MCI, and MCI vs. NC classification problems, with a 4% and a 7% increase in accuracy over the state-of-the-art for AD vs. MCI and MCI vs. NC, respectively. We also provide a detailed analysis of the effect of the intelligent training data selection method, changing the training size, and changing the number of layers to be fine-tuned. Finally, we provide class activation maps (CAM) that demonstrate how the proposed model focuses on discriminative image regions that are neuropathologically relevant and can help the healthcare practitioner in interpreting the model’s decision-making process.","","IEEE Access","1","10.1109/ACCESS.2019.2920448","https://consensus.app/papers/transfer-learning-with-intelligent-training-data-khan/28e8d4ec3a53521bb00539c557895855/"
"Multi-Modality Cascaded Convolutional Neural Networks for Alzheimer’s Disease Diagnosis","The proposed cascaded convolutional neural networks method accurately classifies Alzheimer's disease from normal controls and mild cognitive impairment, with a 93.26% accuracy for AD and 82.95% for pMCI vs. NC.","Manhua Liu, D. Cheng, Kundong Wang, Yaping Wang",2018,239,"Accurate and early diagnosis of Alzheimer’s disease (AD) plays important role for patient care and development of future treatment. Structural and functional neuroimages, such as magnetic resonance images (MRI) and positron emission tomography (PET), are providing powerful imaging modalities to help understand the anatomical and functional neural changes related to AD. In recent years, machine learning methods have been widely studied on analysis of multi-modality neuroimages for quantitative evaluation and computer-aided-diagnosis (CAD) of AD. Most existing methods extract the hand-craft imaging features after image preprocessing such as registration and segmentation, and then train a classifier to distinguish AD subjects from other groups. This paper proposes to construct cascaded convolutional neural networks (CNNs) to learn the multi-level and multimodal features of MRI and PET brain images for AD classification. First, multiple deep 3D-CNNs are constructed on different local image patches to transform the local brain image into more compact high-level features. Then, an upper high-level 2D-CNN followed by softmax layer is cascaded to ensemble the high-level features learned from the multi-modality and generate the latent multimodal correlation features of the corresponding image patches for classification task. Finally, these learned features are combined by a fully connected layer followed by softmax layer for AD classification. The proposed method can automatically learn the generic multi-level and multimodal features from multiple imaging modalities for classification, which are robust to the scale and rotation variations to some extent. No image segmentation and rigid registration are required in pre-processing the brain images. Our method is evaluated on the baseline MRI and PET images of 397 subjects including 93 AD patients, 204 mild cognitive impairment (MCI, 76 pMCI +128 sMCI) and 100 normal controls (NC) from Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Experimental results show that the proposed method achieves an accuracy of 93.26% for classification of AD vs. NC and 82.95% for classification pMCI vs. NC, demonstrating the promising classification performance.","","Neuroinformatics","1","10.1007/s12021-018-9370-4","https://consensus.app/papers/multimodality-cascaded-convolutional-neural-networks-liu/de256b69c1205bdab797a24c0d5da729/"
"A multilayer multimodal detection and prediction model based on explainable artificial intelligence for Alzheimer’s disease","This two-layer model accurately diagnoses Alzheimer's disease and detects progression, providing trustworthy, accountable, and medically applicable results for physicians.","Shaker El-Sappagh, J. M. Alonso, S. Islam, Ahmad M Sultan, K. Kwak",2021,103,"Alzheimer’s disease (AD) is the most common type of dementia. Its diagnosis and progression detection have been intensively studied. Nevertheless, research studies often have little effect on clinical practice mainly due to the following reasons: (1) Most studies depend mainly on a single modality, especially neuroimaging; (2) diagnosis and progression detection are usually studied separately as two independent problems; and (3) current studies concentrate mainly on optimizing the performance of complex machine learning models, while disregarding their explainability. As a result, physicians struggle to interpret these models, and feel it is hard to trust them. In this paper, we carefully develop an accurate and interpretable AD diagnosis and progression detection model. This model provides physicians with accurate decisions along with a set of explanations for every decision. Specifically, the model integrates 11 modalities of 1048 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) real-world dataset: 294 cognitively normal, 254 stable mild cognitive impairment (MCI), 232 progressive MCI, and 268 AD. It is actually a two-layer model with random forest (RF) as classifier algorithm. In the first layer, the model carries out a multi-class classification for the early diagnosis of AD patients. In the second layer, the model applies binary classification to detect possible MCI-to-AD progression within three years from a baseline diagnosis. The performance of the model is optimized with key markers selected from a large set of biological and clinical measures. Regarding explainability, we provide, for each layer, global and instance-based explanations of the RF classifier by using the SHapley Additive exPlanations (SHAP) feature attribution framework. In addition, we implement 22 explainers based on decision trees and fuzzy rule-based systems to provide complementary justifications for every RF decision in each layer. Furthermore, these explanations are represented in natural language form to help physicians understand the predictions. The designed model achieves a cross-validation accuracy of 93.95% and an F1-score of 93.94% in the first layer, while it achieves a cross-validation accuracy of 87.08% and an F1-Score of 87.09% in the second layer. The resulting system is not only accurate, but also trustworthy, accountable, and medically applicable, thanks to the provided explanations which are broadly consistent with each other and with the AD medical literature. The proposed system can help to enhance the clinical understanding of AD diagnosis and progression processes by providing detailed insights into the effect of different modalities on the disease risk.","","Scientific Reports","1","10.1038/s41598-021-82098-3","https://consensus.app/papers/multilayer-detection-prediction-model-based-elsappagh/3b4531fda35f55cdab0bd31dc0a35317/"
"Deep sequence modelling for Alzheimer's disease detection using MRI","Using sequence-based models can improve the classification accuracy of 2D and 3D CNNs for Alzheimer's disease detection by up to 10%.","Amir Ebrahimi, S. Luo, R. Chiong",2021,36,"BACKGROUND
Alzheimer's disease (AD) is one of the deadliest diseases in developed countries. Treatments following early AD detection can significantly delay institutionalisation and extend patients' independence. There has been a growing focus on early AD detection using artificial intelligence. Convolutional neural networks (CNNs) have proven revolutionary for image-based applications and have been applied to brain scans. In recent years, studies have utilised two-dimensional (2D) CNNs on magnetic resonance imaging (MRI) scans for AD detection. To apply a 2D CNN on three-dimensional (3D) MRI volumes, each MRI scan is split into 2D image slices. A CNN is trained over the image slices by calculating a loss function between each subject's label and each image slice's predicted output. Although 2D CNNs can discover spatial dependencies in an image slice, they cannot understand the temporal dependencies among 2D image slices in a 3D MRI volume. This study aims to resolve this issue by modelling the sequence of MRI features produced by a CNN with deep sequence-based networks for AD detection.


METHOD
The CNN utilised in this paper was ResNet-18 pre-trained on an ImageNet dataset. The employed sequence-based models were the temporal convolutional network (TCN) and different types of recurrent neural networks. Several deep sequence-based models and configurations were implemented and compared for AD detection.


RESULTS
Our proposed TCN model achieved the best classification performance with 91.78% accuracy, 91.56% sensitivity and 92% specificity.


CONCLUSION
Our results show that applying sequence-based models can improve the classification accuracy of 2D and 3D CNNs for AD detection by up to 10%.","","Computers in biology and medicine","1","10.1016/j.compbiomed.2021.104537","https://consensus.app/papers/sequence-modelling-alzheimers-disease-detection-using-ebrahimi/36e7952de33650a5a898d2a84ffe3b8f/"
"Enhancing magnetic resonance imaging-driven Alzheimer’s disease classification performance using generative adversarial learning","GAN frameworks can enhance Alzheimer's disease classification performance and improve image quality using MRI scans of different magnetic field strengths.","Xiaoping Zhou, S. Qiu, P. Joshi, Chonghua Xue, R. Killiany, A. Mian, S. Chin, R. Au, V. Kolachalama",2021,32,"Background Generative adversarial networks (GAN) can produce images of improved quality but their ability to augment image-based classification is not fully explored. We evaluated if a modified GAN can learn from magnetic resonance imaging (MRI) scans of multiple magnetic field strengths to enhance Alzheimer’s disease (AD) classification performance. Methods T1-weighted brain MRI scans from 151 participants of the Alzheimer’s Disease Neuroimaging Initiative (ADNI), who underwent both 1.5-Tesla (1.5-T) and 3-Tesla imaging at the same time were selected to construct a GAN model. This model was trained along with a three-dimensional fully convolutional network (FCN) using the generated images (3T*) as inputs to predict AD status. Quality of the generated images was evaluated using signal to noise ratio (SNR), Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE) and Natural Image Quality Evaluator (NIQE). Cases from the Australian Imaging, Biomarker & Lifestyle Flagship Study of Ageing (AIBL, n  = 107) and the National Alzheimer’s Coordinating Center (NACC, n  = 565) were used for model validation. Results The 3T*-based FCN classifier performed better than the FCN model trained using the 1.5-T scans. Specifically, the mean area under curve increased from 0.907 to 0.932, from 0.934 to 0.940, and from 0.870 to 0.907 on the ADNI test, AIBL, and NACC datasets, respectively. Additionally, we found that the mean quality of the generated (3T*) images was consistently higher than the 1.5-T images, as measured using SNR, BRISQUE, and NIQE on the validation datasets. Conclusion This study demonstrates a proof of principle that GAN frameworks can be constructed to augment AD classification performance and improve image quality.","","Alzheimer's Research & Therapy","1","10.1186/s13195-021-00797-5","https://consensus.app/papers/enhancing-resonance-imagingdriven-alzheimer-disease-zhou/d97ac3b942da5303b22f305c6ac5a878/"
"Convolutional Neural Networks for Classification of Alzheimer's Disease: Overview and Reproducible Evaluation","Different 3D CNN approaches for Alzheimer's disease classification from brain imaging data perform similarly, but 2D slice approaches show lower performance.","Junhao Wen, Elina Thibeau-Sutre, J. Samper-González, A. Routier, Simona Bottani, S. Durrleman, Ninon Burgos, O. Colliot",2019,331,"Numerous machine learning (ML) approaches have been proposed for automatic classification of Alzheimer's disease (AD) from brain imaging data. In particular, over 30 papers have proposed to use convolutional neural networks (CNN) for AD classification from anatomical MRI. However, the classification performance is difficult to compare across studies due to variations in components such as participant selection, image preprocessing or validation procedure. Moreover, these studies are hardly reproducible because their frameworks are not publicly accessible and because implementation details are lacking. Lastly, some of these papers may report a biased performance due to inadequate or unclear validation or model selection procedures. In the present work, we aim to address these limitations through three main contributions. First, we performed a systematic literature review. We identified four main types of approaches: i) 2D slice-level, ii) 3D patch-level, iii) ROI-based and iv) 3D subject-level CNN. Moreover, we found that more than half of the surveyed papers may have suffered from data leakage and thus reported biased performance. Our second contribution is the extension of our open-source framework for classification of AD using CNN and T1-weighted MRI. The framework comprises previously developed tools to automatically convert ADNI, AIBL and OASIS data into the BIDS standard, and a modular set of image preprocessing procedures, classification architectures and evaluation procedures dedicated to deep learning. Finally, we used this framework to rigorously compare different CNN architectures. The data was split into training/validation/test sets at the very beginning and only the training/validation sets were used for model selection. To avoid any overfitting, the test sets were left untouched until the end of the peer-review process. Overall, the different 3D approaches (3D-subject, 3D-ROI, 3D-patch) achieved similar performances while that of the 2D slice approach was lower. Of note, the different CNN approaches did not perform better than a SVM with voxel-based features. The different approaches generalized well to similar populations but not to datasets with different inclusion criteria or demographical characteristics. All the code of the framework and the experiments is publicly available: general-purpose tools have been integrated into the Clinica software (www.clinica.run) and the paper-specific code is available at: https://github.com/aramis-lab/AD-DL.","systematic review","Medical image analysis","1","10.1016/j.media.2020.101694","https://consensus.app/papers/neural-networks-classification-alzheimers-disease-wen/f8b6675994ba54b3a71585ae12d20157/"
"An Efficient Deep Neural Network Binary Classifier for Alzheimer’s Disease Classification","The proposed deep neural network model with fully connected layers achieved 85.19% accuracy in Alzheimer's disease classification compared to cognitively normal individuals, Mild Cognitive Impairment, and Mild Cognitive Impairment vs. CN.","Rukesh Prajapati, Uttam Khatri, G. Kwon",2021,12,"In recent research, deep neural networks have better classification results in the medical research fields. In this paper, a deep neural network with fully connected layers is designed to perform binary classification. Three different types of activation functions are used for the hidden layers. After performing k-folds validation with different activation function combinations, a model with the best performance is used. We used feature features extracted from the ADNI image for classification. To determine the best model, an experiment is performed for the classification of two groups: Alzheimer’s Disease (AD) and Cognitively Normal (CN). The proposed DNN with the best validation accuracy score obtained 85.19%, 76.93%, and 72.73% accuracy on the test data for AD vs. CN, Mild Cognitive Impairment (MCI) vs. CN, and AD vs. MCI classifications, respectively. This accuracy score is higher in comparison with other traditional machine learning algorithms.","","2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)","","10.1109/ICAIIC51459.2021.9415212","https://consensus.app/papers/deep-neural-network-binary-classifier-alzheimer-disease-prajapati/d599ad914bc25baa8084907f8353a082/"
"Accurate Detection of Alzheimer’s Disease Using Lightweight Deep Learning Model on MRI Data","Our lightweight deep learning model accurately detects Alzheimer's disease from MRI images, achieving high detection performance without needing deeper layers and reducing complexity.","A. El-latif, S. Chelloug, Maali Alabdulhafith, Mohamed Hammad",2023,6,"Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by cognitive impairment and aberrant protein deposition in the brain. Therefore, the early detection of AD is crucial for the development of effective treatments and interventions, as the disease is more responsive to treatment in its early stages. It is worth mentioning that deep learning techniques have been successfully applied in recent years to a wide range of medical imaging tasks, including the detection of AD. These techniques have the ability to automatically learn and extract features from large datasets, making them well suited for the analysis of complex medical images. In this paper, we propose an improved lightweight deep learning model for the accurate detection of AD from magnetic resonance imaging (MRI) images. Our proposed model achieves high detection performance without the need for deeper layers and eliminates the use of traditional methods such as feature extraction and classification by combining them all into one stage. Furthermore, our proposed method consists of only seven layers, making the system less complex than other previous deep models and less time-consuming to process. We evaluate our proposed model using a publicly available Kaggle dataset, which contains a large number of records in a small dataset size of only 36 Megabytes. Our model achieved an overall accuracy of 99.22% for binary classification and 95.93% for multi-classification tasks, which outperformed other previous models. Our study is the first to combine all methods used in the publicly available Kaggle dataset for AD detection, enabling researchers to work on a dataset with new challenges. Our findings show the effectiveness of our lightweight deep learning framework to achieve high accuracy in the classification of AD.","","Diagnostics","2","10.3390/diagnostics13071216","https://consensus.app/papers/accurate-detection-alzheimer-disease-using-lightweight-ellatif/90212bbb612b59d1a3222246b8235f5a/"
