Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"Learning Domain‐specific Semantic Representation from Weakly Supervised Data to Improve Research Dataset Retrieval","Our proposed domain-specific dense vector representation model improves research dataset retrieval accuracy by about 5% compared to domain-independent fine-tuned models.","Pengcheng Luo, Lingzi Hong, Jimin Wang, Shiqi Wang, Xin Guo, Zheng Gao, Sang Wouk Cho",2022,1,"Along with the development of the data‐driven research paradigm, there are exponentially increasing datasets, which bring challenges to researchers in the efficient retrieval of relevant datasets. Previous studies mainly focused on query expansion methods based on sparse retrieval models to improve the accuracy and recall in retrieval. We investigated the use of semantically rich information to retrieve relevant datasets and the benefits of using domain‐specific dense vector representation as opposed to general representation. First, we used pairs of metadata fields that have semantic relevance to construct the domain‐specific weakly supervised training data. Then, a pre‐trained transformer‐based deep learning model is fine‐tuned on the training data using the contrastive learning method. Finally, dense vector representations of the queries and datasets are obtained based on the fine‐tuned model. The relevance of a dataset to a query is measured by the similarity between the vectors. To evaluate the performance of the proposed model, we collected 104,683 datasets from 13 research data repositories, recruited volunteers to design research‐oriented queries, and annotated the retrieval results. The experimental results show that compared with the domain‐independent fine‐tuned model, our proposed method can improve the NDCG@10 score by about 5%.","","Proceedings of the Association for Information Science and Technology","3","10.1002/pra2.616","https://consensus.app/papers/learning-domain%E2%80%90specific-semantic-representation-luo/6e7e003000915bd990eca8e70bd80bbe/"
"Multi-Source Soft Pseudo-Label Learning with Domain Similarity-based Weighting for Semantic Segmentation","This paper proposes a domain-adjusted training method for semantic segmentation using multiple source datasets, resulting in better performance and applicability to various target environments.","Shigemichi Matsuzaki, Hiroaki Masuzawa, Jun Miura",2023,0,"This paper describes a method of domain adap-tive training for semantic segmentation using multiple source datasets that are not necessarily relevant to the target dataset. We propose a soft pseudo-label generation method by integrating predicted object probabilities from multiple source models. The prediction of each source model is weighted based on the estimated domain similarity between the source and the target datasets to emphasize contribution of a model trained on a source that is more similar to the target and generate reasonable pseudo-labels. We also propose a training method using the soft pseudo-labels considering their entropy to fully exploit information from the source datasets while suppressing the influence of possibly misclassified pixels. The experiments show comparative or better performance than our previous work and another existing multi-source domain adaptation method, and applicability to a variety of target environments.","","2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","","10.1109/IROS55552.2023.10342159","https://consensus.app/papers/multisource-soft-pseudolabel-learning-domain-matsuzaki/893e7ca1c7bb5832abe5ecd04d220946/"
"A Collaborative Alignment Framework of Transferable Knowledge Extraction for Unsupervised Domain Adaptation","The Collaborative Alignment Framework (CAF) effectively reduces global domain discrepancy and preserves local semantic consistency for cross-domain knowledge transfer, outperforming existing methods on popular benchmarks.","Binhui Xie, Shuang Li, Fangrui Lv, Chi Harold Liu, Guoren Wang, Dapeng Wu",2023,31,"Unsupervised domain adaptation (UDA) aims to utilize knowledge from a label-rich source domain to understand a similar yet distinct unlabeled target domain. Notably, global distribution statistics across domains and local semantic characteristics across samples, are two essential factors of data analysis that should be fully explored. Most existing UDA approaches either harness only one of them or fail to closely associate them for efficient adaptation. In this work, we propose a unified framework, called Collaborative Alignment Framework (CAF), which simultaneously reduces the global domain discrepancy and preserves the local semantic consistency for cross-domain knowledge transfer in a collaborative manner. Specifically, for domain-oriented alignment, we utilize adversarial training or minimize the Wasserstein distance between the two distributions to learn domain-level invariant representations. For semantic-oriented matching, we capture the semantic discrepancy between the predictions of two diverse task-specific classifiers and enhance the features of target data to be near the support of the source data class-wisely, which promotes semantic consistency across domains effectively. These two adaptation processes can be deeply intertwined in CAF via collaborative training, thus CAF can learn domain-invariant and semantic-consistent feature representations. Extensive experiments on four popular benchmarks, including DomainNet, VisDA-2017, Office-31, and ImageCLEF, demonstrate the proposed methods significantly outperform the existing methods, especially on the large-scale dataset. The code is available at https://github.com/BIT-DA/CAF.","","IEEE Transactions on Knowledge and Data Engineering","1","10.1109/TKDE.2022.3185233","https://consensus.app/papers/alignment-framework-transferable-knowledge-extraction-xie/b8fca6371e905b38842a61ea41321442/"
"A Cross-Domain Semantic Similarity Measure and Multi-Source Domain Adaptation in Sentiment Analysis","Using enhanced cross-entropy measures in multi-source domain adaptation models improves sentiment analysis accuracy by 3.66% to 9.09% when training on different domains.","Dipak Patel, Kiran R. Amin",2022,2,"Domain adaptation becomes crucial when there is a lack of labelled data in various domains. The accuracy of traditional machine learning models degrades largely if they are trained on one domain (called the source or training domain) and classify the data of a different domain (called the target domain or test domain, which is different from the source domain). The machine needs to train on a corresponding domain to improve the classification accuracy, but labelling each new domain is a complex and time-consuming task. Hence, the domain adaptation technique is required to solve the issue of data labeling. The similarity measure plays a vital role in selecting important pivot features from the target domain that match source domains. This research article has introduced an enhanced cross-entropy measure for matching the normalized frequency distribution of different domains and found an important domain-specific feature set. In addition, the technique of using enhanced cross entropy measures is proposed in the multi-source domain adaptation model to effectively classify the target domain data. The result shows that there is an improvement of 3.66% to 9.09% using our approach.","","2022 International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)","","10.1109/ICAISS55157.2022.10011051","https://consensus.app/papers/crossdomain-semantic-similarity-measure-multisource-patel/ec7c2c2a11405992a291af7b9d9ffefa/"
"Domain-Adversarial Training of Neural Networks","Our new representation learning approach effectively promotes the emergence of features that are both discriminative and indiscriminate, achieving state-of-the-art domain adaptation performance in various classification tasks.","Yaroslav Ganin, E. Ustinova, Hana Ajakan, Pascal Germain, H. Larochelle, François Laviolette, M. Marchand, V. Lempitsky",2015,7156,"We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. 
 
The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. 
 
We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application.","","","1","10.1007/978-3-319-58347-1_10","https://consensus.app/papers/training-neural-networks-ganin/8f88731cef115b8c80d3521984e6c8d3/"
"SePiCo: Semantic-Guided Pixel Contrast for Domain Adaptive Semantic Segmentation","SePiCo enhances domain adaptive semantic segmentation by highlighting semantic concepts of individual pixels, improving discrimination and generalization across domains.","Binhui Xie, Shuang Li, Mingjiang Li, Chi Harold Liu, Gao Huang, Guoren Wang",2022,64,"Domain adaptive semantic segmentation attempts to make satisfactory dense predictions on an unlabeled target domain by utilizing the supervised model trained on a labeled source domain. One popular solution is self-training, which retrains the model with pseudo labels on target instances. Plenty of approaches tend to alleviate noisy pseudo labels, however, they ignore the intrinsic connection of the training data, i.e., intra-class compactness and inter-class dispersion between pixel representations across and within domains. In consequence, they struggle to handle cross-domain semantic variations and fail to build a well-structured embedding space, leading to less discrimination and poor generalization. In this work, we propose Semantic-Guided Pixel Contrast (SePiCo), a novel one-stage adaptation framework that highlights the semantic concepts of individual pixels to promote learning of class-discriminative and class-balanced pixel representations across domains, eventually boosting the performance of self-training methods. Specifically, to explore proper semantic concepts, we first investigate a centroid-aware pixel contrast that employs the category centroids of the entire source domain or a single source image to guide the learning of discriminative features. Considering the possible lack of category diversity in semantic concepts, we then blaze a trail of distributional perspective to involve a sufficient quantity of instances, namely distribution-aware pixel contrast, in which we approximate the true distribution of each semantic category from the statistics of labeled source data. Moreover, such an optimization objective can derive a closed-form upper bound by implicitly involving an infinite number of (dis)similar pairs, making it computationally efficient. Extensive experiments show that SePiCo not only helps stabilize training but also yields discriminative representations, making significant progress on both synthetic-to-real and daytime-to-nighttime adaptation scenarios. The code and models are available at https://github.com/BIT-DA/SePiCo.","","IEEE Transactions on Pattern Analysis and Machine Intelligence","1","10.1109/TPAMI.2023.3237740","https://consensus.app/papers/sepico-semanticguided-pixel-contrast-domain-adaptive-xie/611f3f5c0ebd5b94b8b119867a707a26/"
"MSeg: A Composite Dataset for Multi-Domain Semantic Segmentation","MSeg unifies semantic segmentation datasets from different domains, enabling a single model to function effectively across domains and generalize to datasets not seen during training.","John Lambert, Zhuang Liu, Ozan Sener, James Hays, V. Koltun",2021,143,"We present MSeg, a composite dataset that unifies semantic segmentation datasets from different domains. A naive merge of the constituent datasets yields poor performance due to inconsistent taxonomies and annotation practices. We reconcile the taxonomies and bring the pixel-level annotations into alignment by relabeling more than 220,000 object masks in more than 80,000 images, requiring more than 1.34 years of collective annotator effort. The resulting composite dataset enables training a single semantic segmentation model that functions effectively across domains and generalizes to datasets that were not seen during training. We adopt zero-shot cross-dataset transfer as a benchmark to systematically evaluate a model's robustness and show that MSeg training yields substantially more robust models in comparison to training on individual datasets or naive mixing of datasets without the presented contributions. A model trained on MSeg ranks first on the WildDash-v1 leaderboard for robust semantic segmentation, with no exposure to WildDash data during training. We evaluate our models in the 2020 Robust Vision Challenge (RVC) as an extreme generalization experiment. MSeg training sets include only three of the seven datasets in the RVC; more importantly, the evaluation taxonomy of RVC is different and more detailed. Surprisingly, our model shows competitive performance and ranks second. To evaluate how close we are to the grand aim of robust, efficient, and complete scene understanding, we go beyond semantic segmentation by training instance segmentation and panoptic segmentation models using our dataset. Moreover, we also evaluate various engineering design decisions and metrics, including resolution and computational efficiency. Although our models are far from this grand aim, our comprehensive evaluation is crucial for progress. We share all the models and code with the community.","","IEEE Transactions on Pattern Analysis and Machine Intelligence","1","10.1109/TPAMI.2022.3151200","https://consensus.app/papers/mseg-composite-dataset-multidomain-semantic-lambert/5f8febe463af5880af5b5ddabc8ca56d/"
"Generalizable model-agnostic semantic segmentation via target-specific normalization","The proposed domain generalization framework enhances semantic segmentation performance by utilizing model-agnostic learning and target-specific normalization, improving generalization ability across seen and unseen domains.","Jian Zhang, Lei Qi, Yinghuan Shi, Yang Gao",2020,23,"Semantic segmentation in a supervised learning manner has achieved significant progress in recent years. However, its performance usually drops dramatically due to the data-distribution discrepancy between seen and unseen domains when we directly deploy the trained model to segment the images of unseen (or new coming) domains. To this end, we propose a novel domain generalization framework for the generalizable semantic segmentation task, which enhances the generalization ability of the model from two different views, including the training paradigm and the test strategy. Concretely, we exploit the model-agnostic learning to simulate the domain shift problem, which deals with the domain generalization from the training scheme perspective. Besides, considering the data-distribution discrepancy between seen source and unseen target domains, we develop the target-specific normalization scheme to enhance the generalization ability. Furthermore, when images come one by one in the test stage, we design the image-based memory bank (Image Bank in short) with style-based selection policy to select similar images to obtain more accurate statistics of normalization. Extensive experiments highlight that the proposed method produces state-of-the-art performance for the domain generalization of semantic segmentation on multiple benchmark segmentation datasets, i.e., Cityscapes, Mapillary. ∗Corresponding author: Yinghuan Shi (syh@nju.edu.cn) and Lei Qi (qilei@seu.edu.cn) Preprint submitted to Pattern Recognition September 1, 2021 ar X iv :2 00 3. 12 29 6v 2 [ cs .C V ] 3 1 A ug 2 02 1","","Pattern Recognit.","1","10.1016/j.patcog.2021.108292","https://consensus.app/papers/segmentation-targetspecific-normalization-zhang/ef127129cccd5bfcb54864c2a3118dbc/"
"Rectifying Pseudo Label Learning via Uncertainty Estimation for Domain Adaptive Semantic Segmentation","The proposed method, which estimates prediction uncertainty during training, significantly improves unsupervised semantic segmentation adaptation and achieves competitive performance on various benchmarks.","Zhedong Zheng, Yi Yang",2020,347,"This paper focuses on the unsupervised domain adaptation of transferring the knowledge from the source domain to the target domain in the context of semantic segmentation. Existing approaches usually regard the pseudo label as the ground truth to fully exploit the unlabeled target-domain data. Yet the pseudo labels of the target-domain data are usually predicted by the model trained on the source domain. Thus, the generated labels inevitably contain the incorrect prediction due to the discrepancy between the training domain and the test domain, which could be transferred to the final adapted model and largely compromises the training process. To overcome the problem, this paper proposes to explicitly estimate the prediction uncertainty during training to rectify the pseudo label learning for unsupervised semantic segmentation adaptation. Given the input image, the model outputs the semantic segmentation prediction as well as the uncertainty of the prediction. Specifically, we model the uncertainty via the prediction variance and involve the uncertainty into the optimization objective. To verify the effectiveness of the proposed method, we evaluate the proposed method on two prevalent synthetic-to-real semantic segmentation benchmarks, i.e., GTA5 $$\rightarrow $$ → Cityscapes and SYNTHIA $$\rightarrow $$ → Cityscapes, as well as one cross-city benchmark, i.e., Cityscapes $$\rightarrow $$ → Oxford RobotCar. We demonstrate through extensive experiments that the proposed approach (1) dynamically sets different confidence thresholds according to the prediction variance, (2) rectifies the learning from noisy pseudo labels, and (3) achieves significant improvements over the conventional pseudo label learning and yields competitive performance on all three benchmarks.","","International Journal of Computer Vision","1","10.1007/s11263-020-01395-y","https://consensus.app/papers/rectifying-pseudo-label-learning-uncertainty-estimation-zheng/5e97238dda715337b057008170b4d35e/"
"Cross Domain Lifelong Learning Based on Task Similarity","The Cross-Domain Lifelong Learning (CDLL) framework effectively reduces catastrophic forgetting and enhances performance across different domains, more closely aligning with human learning.","Shuojin Yang, Z. Cai",2023,2,"Humans gradually learn a sequence of cross-domain tasks and seldom experience catastrophic forgetting. In contrast, deep neural networks achieve good performance only in specific tasks within a single domain. To equip the network with lifelong learning capabilities, we propose a Cross-Domain Lifelong Learning (CDLL) framework that fully explores task similarities. Specifically, we employ a Dual Siamese Network (DSN) to learn the essential similarity features of tasks across different domains. To further understand similarity information across domains, we introduce a Domain-Invariant Feature Enhancement Module (DFEM) to better extract domain-invariant features. Moreover, we propose a Spatial Attention Network (SAN) that assigns different weights to various tasks based on the learned similarity features. Ultimately, to maximize the use of model parameters for learning new tasks, we propose a Structural Sparsity Loss (SSL) that can make the SAN as sparse as possible while ensuring accuracy. Experimental results show that our method effectively reduces catastrophic forgetting compared with state-of-the-art methods when continuously learning multiple tasks across different domains. It is worth noting that the proposed method scarcely forgets old knowledge while consistently enhancing the performance of learned tasks, more closely aligning with human learning.","","IEEE Transactions on Pattern Analysis and Machine Intelligence","1","10.1109/TPAMI.2023.3276991","https://consensus.app/papers/cross-domain-lifelong-learning-based-task-similarity-yang/c23be7d3cead5f18b7cacdec7dc325ef/"
