Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"Enhancing Abstractive Summarization with Extracted Knowledge Graphs and Multi-Source Transformers","This research enhances abstractive summarization by incorporating extracted knowledge graph information and structured semantics, improving the quality of information generated by large language models.","Tong Chen, Xuewei Wang, Tianwei Yue, Xiaoyu Bai, Cindy X. Le, Wenping Wang",2023,5,"As the popularity of large language models (LLMs) has risen over the course of the last year, led by GPT-3/4 and especially its productization as ChatGPT, we have witnessed the extensive application of LLMs to text summarization. However, LLMs do not intrinsically have the power to verify the correctness of the information they supply and generate. This research introduces a novel approach to abstractive summarization, aiming to address the limitations of LLMs in that they struggle to understand the truth. The proposed method leverages extracted knowledge graph information and structured semantics as a guide for summarization. Building upon BART, one of the state-of-the-art sequence-to-sequence pre-trained LLMs, multi-source transformer modules are developed as an encoder, which are capable of processing textual and graphical inputs. Decoding is performed based on this enriched encoding to enhance the summary quality. The Wiki-Sum dataset, derived from Wikipedia text dumps, is introduced for evaluation purposes. Comparative experiments with baseline models demonstrate the strengths of the proposed approach in generating informative and relevant summaries. We conclude by presenting our insights into utilizing LLMs with graph external information, which will become a powerful aid towards the goal of factually correct and verified LLMs.","","Applied Sciences","2","10.3390/app13137753","https://consensus.app/papers/enhancing-summarization-extracted-knowledge-graphs-chen/7544a783e10453629faf6676439c6303/"
"Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs","Large Language Models (LLMs) show potential in learning on graphs, particularly node classification, by enhancing node text attributes and acting as standalone predictors.","Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Haifang Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, Jiliang Tang",2023,39,"Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at https://github.com/CurryTang/Graph-LLM.","","ArXiv","","10.48550/arXiv.2307.03393","https://consensus.app/papers/exploring-potential-large-language-models-llms-learning-chen/37c1ba56008f5284b2b53c017f69ae3c/"
"Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering","Our LLM-KG-Bench framework effectively evaluates Large Language Models in knowledge graph engineering, improving their performance in syntax, error correction, facts extraction, and dataset generation.","Lars Meyer, Johannes Frey, K. Junghanns, Felix Brei, Kirill Bulert, Sabine Grunder-Fahrer, Michael Martin",2023,1,"As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance.","","ArXiv","","10.48550/arXiv.2308.16622","https://consensus.app/papers/developing-benchmark-assessing-large-language-models-meyer/6e8f7907779352c5989ffd3ea9cb5054/"
"Exploring Large Language Models for Knowledge Graph Completion","Large Language Models (LLM) can effectively complete knowledge graphs, improving performance in tasks like triple classification and relation prediction.","Liang Yao, Jiazhen Peng, Chengsheng Mao, Yuan Luo",2023,3,"Knowledge graphs play a vital role in numerous artificial intelligence tasks, yet they frequently face the issue of incompleteness. In this study, we explore utilizing Large Language Models (LLM) for knowledge graph completion. We consider triples in knowledge graphs as text sequences and introduce an innovative framework called Knowledge Graph LLM (KG-LLM) to model these triples. Our technique employs entity and relation descriptions of a triple as prompts and utilizes the response for predictions. Experiments on various benchmark knowledge graphs demonstrate that our method attains state-of-the-art performance in tasks such as triple classification and relation prediction. We also find that fine-tuning relatively smaller models (e.g., LLaMA-7B, ChatGLM-6B) outperforms recent ChatGPT and GPT-4.","","ArXiv","","10.48550/arXiv.2308.13916","https://consensus.app/papers/exploring-language-models-knowledge-graph-completion-yao/b8b9041413ee5284b6831190235f0c7b/"
"LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities","GPT-4 outperforms ChatGPT in most Knowledge Graph construction tasks, and AutoKG, a multi-agent-based approach, shows potential for future advancements in Knowledge Graph construction and reasoning.","Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang",2023,17,"This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our findings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses fine-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this field and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable insights for future undertakings of KG\footnote{Code and datasets will be available in https://github.com/zjunlp/AutoKG.","","ArXiv","","10.48550/arXiv.2305.13168","https://consensus.app/papers/llms-knowledge-graph-construction-reasoning-recent-zhu/bc301ddc6b135419a9743367f3b5545c/"
"RECALL: A Benchmark for LLMs Robustness against External Counterfactual Knowledge","Existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to alleviating this issue.","Yi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun",2023,1,"LLMs and AI chatbots have improved people's efficiency in various fields. However, the necessary knowledge for answering the question may be beyond the models' knowledge boundaries. To mitigate this issue, many researchers try to introduce external knowledge, such as knowledge graphs and Internet contents, into LLMs for up-to-date information. However, the external information from the Internet may include counterfactual information that will confuse the model and lead to an incorrect response. Thus there is a pressing need for LLMs to possess the ability to distinguish reliable information from external knowledge. Therefore, to evaluate the ability of LLMs to discern the reliability of external knowledge, we create a benchmark from existing knowledge bases. Our benchmark consists of two tasks, Question Answering and Text Generation, and for each task, we provide models with a context containing counterfactual information. Evaluation results show that existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to the alleviation of this issue.","","ArXiv","","10.48550/arXiv.2311.08147","https://consensus.app/papers/recall-benchmark-llms-robustness-external-liu/2e3cc9fd7531541c8634964889d12e41/"
"Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning","Reasoning on graphs (RoG) synergizes large language models with knowledge graphs to enable faithful and interpretable reasoning, improving their performance and trustworthiness in complex tasks.","Linhao Luo, Yuan-Fang Li, Gholamreza Haffari, Shirui Pan",2023,10,"Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results.","","ArXiv","","10.48550/arXiv.2310.01061","https://consensus.app/papers/reasoning-graphs-faithful-interpretable-large-language-luo/67bc2ddc11b15fde93e4e90f135f73b4/"
"Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction","Our innovative knowledge graph generation approach, using large language models like GPT-3.5, provides scalable and versatile construction without the need for external resources or human expertise.","S. Carta, Alessandro Giuliani, L. piano, Alessandro Sebastian Podda, Livio Pompianu, Sandro Gabriele Tiddia",2023,6,"In the current digitalization era, capturing and effectively representing knowledge is crucial in most real-world scenarios. In this context, knowledge graphs represent a potent tool for retrieving and organizing a vast amount of information in a properly interconnected and interpretable structure. However, their generation is still challenging and often requires considerable human effort and domain expertise, hampering the scalability and flexibility across different application fields. This paper proposes an innovative knowledge graph generation approach that leverages the potential of the latest generative large language models, such as GPT-3.5, that can address all the main critical issues in knowledge graph building. The approach is conveyed in a pipeline that comprises novel iterative zero-shot and external knowledge-agnostic strategies in the main stages of the generation process. Our unique manifold approach may encompass significant benefits to the scientific community. In particular, the main contribution can be summarized by: (i) an innovative strategy for iteratively prompting large language models to extract relevant components of the final graph; (ii) a zero-shot strategy for each prompt, meaning that there is no need for providing examples for""guiding""the prompt result; (iii) a scalable solution, as the adoption of LLMs avoids the need for any external resources or human expertise. To assess the effectiveness of our proposed model, we performed experiments on a dataset that covered a specific domain. We claim that our proposal is a suitable solution for scalable and versatile knowledge graph construction and may be applied to different and novel contexts.","","ArXiv","","10.48550/arXiv.2307.01128","https://consensus.app/papers/zeroshot-prompting-knowledge-graph-construction-carta/9ef7b532b94652c5b64e01bca5988334/"
"Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering","Our Knowledge-Augmented Language Model Prompting (KAPING) framework improves knowledge graph question answering by up to 48% on average, without needing model training.","Jinheon Baek, Alham Fikri Aji, Amir Saffari",2023,29,"Large Language Models (LLMs) are capable of performing zero-shot closed-book question answering tasks, based on their internal knowledge stored in parameters during pre-training. However, such internalized knowledge might be insufficient and incorrect, which could lead LLMs to generate factually wrong answers. Furthermore, fine-tuning LLMs to update their knowledge is expensive. To this end, we propose to augment the knowledge directly in the input of LLMs. Specifically, we first retrieve the relevant facts to the input question from the knowledge graph based on semantic similarities between the question and its associated facts. After that, we prepend the retrieved facts to the input question in the form of the prompt, which is then forwarded to LLMs to generate the answer. Our framework, Knowledge-Augmented language model PromptING (KAPING), requires no model training, thus completely zero-shot. We validate the performance of our KAPING framework on the knowledge graph question answering task, that aims to answer the user’s question based on facts over a knowledge graph, on which ours outperforms relevant zero-shot baselines by up to 48% in average, across multiple LLMs of various sizes.","","ArXiv","","10.48550/arXiv.2306.04136","https://consensus.app/papers/knowledgeaugmented-language-model-prompting-zeroshot-baek/2ce2f5b23b7950a298279cb9ed7645d6/"
"Think-on-Graph: Deep and Responsible Reasoning of Large Language Model with Knowledge Graph","Think-on-Graph (ToG) enhances large language models' ability for deep and responsible reasoning by using knowledge graphs, improving performance in complex tasks without additional training costs.","Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Sai Wang, Chen Lin, Yeyun Gong, H. Shum, Jian Guo",2023,11,"Large language models (LLMs) have made signiﬁcant strides in various tasks, yet they often struggle with complex reasoning and exhibit poor performance in scenarios where knowledge traceability, timeliness, and accuracy are crucial. To address these limitations, we present Think-on-Graph (ToG), a novel framework that leverages knowledge graphs to enhance LLMs’ ability for deep and responsible reasoning. By employing ToG, we can identify entities relevant to a given question and conduct exploration and reasoning to retrieve related triples from an external knowledge database. This iterative procedure generates multiple reasoning pathways consisting of sequentially connected triplets until sufﬁcient information is gathered to answer the question or the maximum depth is reached. Through experiments on complex multi-hop reasoning question-answering tasks, we demonstrate that ToG outperforms existing methods, effectively addressing the aforementioned limitations of LLMs without incurring additional training costs.","","ArXiv","","10.48550/arXiv.2307.07697","https://consensus.app/papers/thinkongraph-deep-responsible-reasoning-large-language-sun/041c1cc34f5953e28230e8cf1bbf67ee/"
