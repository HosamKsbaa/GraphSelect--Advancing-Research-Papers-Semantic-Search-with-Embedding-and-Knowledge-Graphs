Title,Takeaway,Authors,Year,Citations,Abstract,Study Type,Journal,Journal SJR Quartile,DOI,Consensus Link
"Deep Learning in Alzheimer's Disease: Diagnostic Classification and Prognostic Prediction Using Neuroimaging Data","Deep learning approaches show promise for diagnostic classification of Alzheimer's disease using multimodal neuroimaging data, with the best performance achieved when combining multimodal neuroimaging and fluid biomarkers.","T. Jo, K. Nho, A. Saykin",2019,352,"Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8% for AD classification and 83.7% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0% for AD classification and 84.2% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as—omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms.","systematic review","Frontiers in Aging Neuroscience","1","10.3389/fnagi.2019.00220","https://consensus.app/papers/deep-learning-alzheimers-disease-diagnostic-jo/c09b595ff18b50feadfdb073214e1779/"
"Deep learning to detect Alzheimer's disease from neuroimaging: A systematic literature review","Deep learning has shown promising results in detecting Alzheimer's disease from neuroimaging data, but limitations remain in dataset availability and training procedures.","A. E. Ghahnavieh, S. Luo, R. Chiong",2019,172,"Alzheimer's Disease (AD) is one of the leading causes of death in developed countries. From a research point of view, impressive results have been reported using computer-aided algorithms, but clinically no practical diagnostic method is available. In recent years, deep models have become popular, especially in dealing with images. Since 2013, deep learning has begun to gain considerable attention in AD detection research, with the number of published papers in this area increasing drastically since 2017. Deep models have been reported to be more accurate for AD detection compared to general machine learning techniques. Nevertheless, AD detection is still challenging, and for classification, it requires a highly discriminative feature representation to separate similar brain patterns. This paper reviews the current state of AD detection using deep learning. Through a systematic literature review of over 100 articles, we set out the most recent findings and trends. Specifically, we review useful biomarkers and features (personal information, genetic data, and brain scans), the necessary pre-processing steps, and different ways of dealing with neuroimaging data originating from single-modality and multi-modality studies. Deep models and their performance are described in detail. Although deep learning has achieved notable performance in detecting AD, there are several limitations, especially regarding the availability of datasets and training procedures.","systematic review","Computer methods and programs in biomedicine","1","10.1016/j.cmpb.2019.105242","https://consensus.app/papers/deep-learning-alzheimers-disease-neuroimaging-ghahnavieh/370e9f3254d85318973ec8e1669005ff/"
"Classification of Alzheimer’s Disease Using Deep Convolutional Spiking Neural Network","Our deep convolutional Spiking Neural Network-based pipeline effectively classifies Alzheimer's Disease using MRI scans, outperforming comparable methods and showing promising results.","Regina Esi Turkson, Hong Qu, C. Mawuli, M. J. Eghan",2021,24,"Diagnosing Alzheimer’s Disease (AD) in older people using magnetic resonance imaging (MRI) is quite hard since it requires the extraction of highly discriminative feature representation from similar brain patterns and pixel intensities. However, deep learning techniques possess the capability of extracting relevant representations from data. In this work, we designed a novel spiking deep convolutional neural network-based pipeline to classify AD using MRI scans. We considered three MRI scan groups (patients with AD dementia, Mild Cognitive Impairment (MCI), and healthy controls (NC)). We developed a three-binary classification task (AD vs. NC, AD vs. MCI, and NC vs. MCI) for the AD classification tasks. Specifically, an unsupervised convolutional Spiking Neural Networks (SNN) is pre-trained on the MRI scans. Finally, a supervised deep Convolution Neural Network (CNN) is trained on the output of the SNN for the classification tasks. Experiments are performed using the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, and promising results are obtained for the AD classification tasks. We present our proposed model results for both the unsupervised spike pre-training technique and the case where the pre-training technique was not considered, thus serving as a baseline. The accuracy of the proposed model with spike pre-training techniques for the three-binary classification are 90.15%, 87.30%, and 83.90%, respectively, and the accuracy of the model without the spike are 86.90%, 83.25%, and 76.70%, respectively, with a noticeable increase in accuracy and thus, reveals the effectiveness of the proposed method. We also evaluated the robustness of our proposed approach by running experiment on six baseline methods using our preprocessed MRI scans. Our model outperformed almost all the comparable methods due to the robust discriminative capability of the SNN in extracting relevant AD features for the AD classification task.","","Neural Processing Letters","2","10.1007/s11063-021-10514-w","https://consensus.app/papers/classification-alzheimer-disease-using-deep-turkson/6d414fb46cba57dba87f3637b1ca792d/"
"Convolutional Neural Networks for Classification of Alzheimer's Disease: Overview and Reproducible Evaluation","Different 3D CNN approaches for Alzheimer's disease classification from brain imaging data perform similarly, but 2D slice approaches show lower performance.","Junhao Wen, Elina Thibeau-Sutre, J. Samper-González, A. Routier, Simona Bottani, S. Durrleman, Ninon Burgos, O. Colliot",2019,331,"Numerous machine learning (ML) approaches have been proposed for automatic classification of Alzheimer's disease (AD) from brain imaging data. In particular, over 30 papers have proposed to use convolutional neural networks (CNN) for AD classification from anatomical MRI. However, the classification performance is difficult to compare across studies due to variations in components such as participant selection, image preprocessing or validation procedure. Moreover, these studies are hardly reproducible because their frameworks are not publicly accessible and because implementation details are lacking. Lastly, some of these papers may report a biased performance due to inadequate or unclear validation or model selection procedures. In the present work, we aim to address these limitations through three main contributions. First, we performed a systematic literature review. We identified four main types of approaches: i) 2D slice-level, ii) 3D patch-level, iii) ROI-based and iv) 3D subject-level CNN. Moreover, we found that more than half of the surveyed papers may have suffered from data leakage and thus reported biased performance. Our second contribution is the extension of our open-source framework for classification of AD using CNN and T1-weighted MRI. The framework comprises previously developed tools to automatically convert ADNI, AIBL and OASIS data into the BIDS standard, and a modular set of image preprocessing procedures, classification architectures and evaluation procedures dedicated to deep learning. Finally, we used this framework to rigorously compare different CNN architectures. The data was split into training/validation/test sets at the very beginning and only the training/validation sets were used for model selection. To avoid any overfitting, the test sets were left untouched until the end of the peer-review process. Overall, the different 3D approaches (3D-subject, 3D-ROI, 3D-patch) achieved similar performances while that of the 2D slice approach was lower. Of note, the different CNN approaches did not perform better than a SVM with voxel-based features. The different approaches generalized well to similar populations but not to datasets with different inclusion criteria or demographical characteristics. All the code of the framework and the experiments is publicly available: general-purpose tools have been integrated into the Clinica software (www.clinica.run) and the paper-specific code is available at: https://github.com/aramis-lab/AD-DL.","systematic review","Medical image analysis","1","10.1016/j.media.2020.101694","https://consensus.app/papers/neural-networks-classification-alzheimers-disease-wen/f8b6675994ba54b3a71585ae12d20157/"
"Reproducible evaluation of classification methods in Alzheimer's disease: Framework and application to MRI and PET data","The proposed framework for reproducible and objective Alzheimer's disease classification experiments using public datasets, shows that FDG PET outperforms T1 MRI and linear SVM and L2-logistic regression perform similarly.","J. Samper-González, Ninon Burgos, Simona Bottani, S. Fontanella, Pascal Lu, Arnaud Marcoux, A. Routier, J. Guillon, Michael Bacci, Junhao Wen, A. Bertrand, H. Bertin, M. Habert, S. Durrleman, T. Evgeniou, O. Colliot, Alzheimer's Disease Neuroimaging Initiative",2018,132,"&NA; A large number of papers have introduced novel machine learning and feature extraction methods for automatic classification of Alzheimer's disease (AD). However, while the vast majority of these works use the public dataset ADNI for evaluation, they are difficult to reproduce because different key components of the validation are often not readily available. These components include selected participants and input data, image preprocessing and cross‐validation procedures. The performance of the different approaches is also difficult to compare objectively. In particular, it is often difficult to assess which part of the method (e.g. preprocessing, feature extraction or classification algorithms) provides a real improvement, if any. In the present paper, we propose a framework for reproducible and objective classification experiments in AD using three publicly available datasets (ADNI, AIBL and OASIS). The framework comprises: i) automatic conversion of the three datasets into a standard format (BIDS); ii) a modular set of preprocessing pipelines, feature extraction and classification methods, together with an evaluation framework, that provide a baseline for benchmarking the different components. We demonstrate the use of the framework for a large‐scale evaluation on 1960 participants using T1 MRI and FDG PET data. In this evaluation, we assess the influence of different modalities, preprocessing, feature types (regional or voxel‐based features), classifiers, training set sizes and datasets. Performances were in line with the state‐of‐the‐art. FDG PET outperformed T1 MRI for all classification tasks. No difference in performance was found for the use of different atlases, image smoothing, partial volume correction of FDG PET images, or feature type. Linear SVM and L2‐logistic regression resulted in similar performance and both outperformed random forests. The classification performance increased along with the number of subjects used for training. Classifiers trained on ADNI generalized well to AIBL and OASIS. All the code of the framework and the experiments is publicly available: general‐purpose tools have been integrated into the Clinica software (www.clinica.run) and the paper‐specific code is available at: https://gitlab.icm‐institute.org/aramislab/AD‐ML.","","NeuroImage","1","10.1016/j.neuroimage.2018.08.042","https://consensus.app/papers/evaluation-classification-methods-alzheimers-disease-sampergonz%C3%A1lez/18f88b91f81c5397833a87e1f11b5b4c/"
"A Comprehensive Study of Alzheimer's Disease Classification Using Convolutional Neural Networks","Most popular convolutional neural network models for Alzheimer's disease classification from brain MRI scans perform similarly, with 3D models improving accuracy by 1% and pre-training yielding minimal improvement.","Ziqiang Guan, Ritesh Kumar, Y. Fung, Y. Wu, M. Fiterau",2019,13,"A plethora of deep learning models have been developed for the task of Alzheimer's disease classification from brain MRI scans. Many of these models report high performance, achieving three-class classification accuracy of up to 95%. However, it is common for these studies to draw performance comparisons between models that are trained on different subsets of a dataset or use varying imaging preprocessing techniques, making it difficult to objectively assess model performance. Furthermore, many of these works do not provide details such as hyperparameters, the specific MRI scans used, or their source code, making it difficult to replicate their experiments. To address these concerns, we present a comprehensive study of some of the deep learning methods and architectures on the full set of images available from ADNI. We find that, (1) classification using 3D models gives an improvement of 1% in our setup, at the cost of significantly longer training time and more computation power, (2) with our dataset, pre-training yields minimal ($<0.5\%$) improvement in model performance, (3) most popular convolutional neural network models yield similar performance when compared to each other. Lastly, we briefly compare the effects of two image preprocessing programs: FreeSurfer and Clinica, and find that the spatially normalized and segmented outputs from Clinica increased the accuracy of model prediction from 63% to 89% when compared to FreeSurfer images.","","ArXiv","","","https://consensus.app/papers/comprehensive-study-alzheimers-disease-classification-guan/7a96702138ee5b5a84013400dd11216d/"
"Multi -Classification based Alzheimer's Disease Detection with Comparative Analysis from Brain MRI Scans using Deep Learning","Our multi-classification model using brain MRI scans shows over 80% accuracy in detecting Alzheimer's disease, outperforming existing models like Inception V3 and VGG19.","Azmain Kabir, Farishta Kabir, Md. Abu Hasib Mahmud, Sanzida Alam Sinthia, S. M. R. Azam, Emtiaz Hussain, M. Parvez",2021,4,"The neurodegenerative Alzheimer's Disease is the most widely recognized cause of ‘Dementia’ and was allegedly the 7th highest cause of death globally. Yet, there is still no conclusive test for distinguishing Alzheimer's disease. Our proposed model eliminates these challenges in a significant manner. The technique is fit for investigating and analyzing different classes in a single setting and requires significantly less previous apprehension. Several handcrafted or predefined machine learning and deep learning models have been imple-mented in this field of study. Our proposed multi-classification model is primarily implemented based on the Open Access Series of Imaging Studies (OASIS) data and suggests an 18-layer architecture. We have implemented a unique preprocessing approach using all three anatomical planes of the MRI scans in a single sequential model, which was also evaluated afterwards. The research also explores a comparative study among multiple and binary classes in terms of performance and efficiency. Pre-defined models such as Inception V3and VGG19 have also been brought to comparison to measure the model's reliability. Our multiclass setting shows an accuracy of over 80%, which is higher than most of the existing multi-classification models in this dataset. Moreover, the in-depth comparative study using binary classification shows a significant accuracy of over 92%, which ensures the all-around efficacy of the model.","","TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)","","10.1109/TENCON54134.2021.9707313","https://consensus.app/papers/multi-classification-based-alzheimers-disease-detection-kabir/d4228b762a315699ab6252b09eaa9db2/"
"Deep Learning-Based Classification and Voxel-Based Visualization of Frontotemporal Dementia and Alzheimer’s Disease","Deep learning-based networks can accurately differentiate between FTD and Alzheimer's disease from normal controls, providing new insights into their understanding.","Jingjing Hu, Z. Qing, Renyuan Liu, Xin Zhang, Pin Lv, Maoxue Wang, Yang Wang, Kelei He, Yang Gao, Bing Zhang",2021,29,"Frontotemporal dementia (FTD) and Alzheimer’s disease (AD) have overlapping symptoms, and accurate differential diagnosis is important for targeted intervention and treatment. Previous studies suggest that the deep learning (DL) techniques have the potential to solve the differential diagnosis problem of FTD, AD and normal controls (NCs), but its performance is still unclear. In addition, existing DL-assisted diagnostic studies still rely on hypothesis-based expert-level preprocessing. On the one hand, it imposes high requirements on clinicians and data themselves; On the other hand, it hinders the backtracking of classification results to the original image data, resulting in the classification results cannot be interpreted intuitively. In the current study, a large cohort of 3D T1-weighted structural magnetic resonance imaging (MRI) volumes (n = 4,099) was collected from two publicly available databases, i.e., the ADNI and the NIFD. We trained a DL-based network directly based on raw T1 images to classify FTD, AD and corresponding NCs. And we evaluated the convergence speed, differential diagnosis ability, robustness and generalizability under nine scenarios. The proposed network yielded an accuracy of 91.83% based on the most common T1-weighted sequence [magnetization-prepared rapid acquisition with gradient echo (MPRAGE)]. The knowledge learned by the DL network through multiple classification tasks can also be used to solve subproblems, and the knowledge is generalizable and not limited to a specified dataset. Furthermore, we applied a gradient visualization algorithm based on guided backpropagation to calculate the contribution graph, which tells us intuitively why the DL-based networks make each decision. The regions making valuable contributions to FTD were more widespread in the right frontal white matter regions, while the left temporal, bilateral inferior frontal and parahippocampal regions were contributors to the classification of AD. Our results demonstrated that DL-based networks have the ability to solve the enigma of differential diagnosis of diseases without any hypothesis-based preprocessing. Moreover, they may mine the potential patterns that may be different from human clinicians, which may provide new insight into the understanding of FTD and AD.","","Frontiers in Neuroscience","2","10.3389/fnins.2020.626154","https://consensus.app/papers/deep-learningbased-classification-voxelbased-hu/81fdc298224a5053b026e186b7df5944/"
"Prediction and Classification of Alzheimer’s Disease using Deep Learning","Deep learning techniques, such as Convolutional Neural Networks, can effectively predict and classify different stages of Alzheimer's disease using MRI scan images.","M. Jagadeeswari, S. Priya, K. Athira, M. Dhanalakshmi, P. G. Shree",2022,0,"The goal of this study is to predict the different stages of Alzheimer’s using deep learning which is a cutting edge machine learning technique. Alzheimer is a neurodegenerative disease that affects many people especially elders. Hence the early detection of Alzheimer helps in controlling the disease. In the recent years, the diagnosis of Alzheimer has become one of the challenging problems in medical field. Deep learning is an efficient technique to predict it in its early stages. The MRI scan images is taken as the input dataset. The Convolutional neural network was used for preprocessing and training the given dataset. The system's main purpose is to detect Dementia in different patients based on various categories. The technique was developed using Magnetic Resonance Imaging (MRI) data from Kaggle and Open Access Series of Imaging Studies (OASIS). The OASIS dataset has a dimension of 300 rows x 15 columns of patients’ data on different stages of Alzheimer’s. Various performance criteria, such as accuracy, precision, Recall and F1 score, are evaluated for the OASIS Dataset. Different classifiers are used to discover the appropriate parameters for each model, including Logistic Regression, KNN, Decision Tree, Neural Network, Random Forests, and Gradient Boosting to predict the different stages of Alzheimer disease.","","2022 3rd International Conference on Electronics and Sustainable Communication Systems (ICESC)","","10.1109/ICESC54411.2022.9885594","https://consensus.app/papers/prediction-classification-alzheimer-disease-using-deep-jagadeeswari/75514244fa165a4493649534ff34a7f5/"
"Multimodal deep learning models for early detection of Alzheimer’s disease stage","Deep learning models combining imaging, genetic, and clinical data improve early detection of Alzheimer's disease stages.","Janani Venugopalan, L. Tong, H. Hassanzadeh, May D. Wang",2021,231,"Most current Alzheimer’s disease (AD) and mild cognitive disorders (MCI) studies use single data modality to make predictions such as AD stages. The fusion of multiple data modalities can provide a holistic view of AD staging analysis. Thus, we use deep learning (DL) to integrally analyze imaging (magnetic resonance imaging (MRI)), genetic (single nucleotide polymorphisms (SNPs)), and clinical test data to classify patients into AD, MCI, and controls (CN). We use stacked denoising auto-encoders to extract features from clinical and genetic data, and use 3D-convolutional neural networks (CNNs) for imaging data. We also develop a novel data interpretation method to identify top-performing features learned by the deep-models with clustering and perturbation analysis. Using Alzheimer’s disease neuroimaging initiative (ADNI) dataset, we demonstrate that deep models outperform shallow models, including support vector machines, decision trees, random forests, and k-nearest neighbors. In addition, we demonstrate that integrating multi-modality data outperforms single modality models in terms of accuracy, precision, recall, and meanF1 scores. Our models have identified hippocampus, amygdala brain areas, and the Rey Auditory Verbal Learning Test (RAVLT) as top distinguished features, which are consistent with the known AD literature.","","Scientific Reports","1","10.1038/s41598-020-74399-w","https://consensus.app/papers/multimodal-learning-models-detection-alzheimer-disease-venugopalan/0f1cc4babfda53d1a5f622c960d0071e/"
